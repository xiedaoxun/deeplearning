{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================DCGAN========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "# from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集在网盘deeplearning/gan下的faces\n",
    "data_path = 'dataset_gan/data/' # 数据集存放路径\n",
    "num_workers = 1 # 多进程加载数据所用的进程数\n",
    "image_size = 96 # 图片尺寸\n",
    "batch_size = 128\n",
    "max_epoch =  200\n",
    "lr1 = 2e-4 # 生成器的学习率\n",
    "lr2 = 2e-4 # 判别器的学习率\n",
    "beta1=0.5 # Adam优化器的beta1参数\n",
    "gpu=False # 是否使用GPU --nogpu或者--gpu=False不使用gpu\n",
    "nz=100 # 噪声维度\n",
    "ngf = 64 # 生成器feature map数\n",
    "ndf = 64 # 判别器feature map数\n",
    "    \n",
    "save_path = 'dataset_gan/train_result/dcgan/' #训练时生成图片保存路径\n",
    "    \n",
    "# vis = False # 是否使用visdom可视化\n",
    "# env = 'GAN' # visdom的env\n",
    "plot_every = 20 # 每间隔20 batch，visdom画图一次\n",
    "save_every = 3\n",
    "# debug_file='/tmp/debuggan' # 存在该文件则进入debug模式\n",
    "d_every=1 # 每1个batch训练一次判别器\n",
    "g_every=5 # 每5个batch训练一次生成器\n",
    "decay_every=10 # 没10个epoch保存一次模型\n",
    "netd_path = 'dataset_gan/models/netd_last.pth' #预训练模型\n",
    "netg_path = 'dataset_gan/models/netg_last.pth'\n",
    "    \n",
    "# 只测试不训练\n",
    "gen_img = 'result.png'\n",
    "# 从512张生成的图片中保存最好的64张\n",
    "gen_num = 64 \n",
    "gen_search_num = 512 \n",
    "gen_mean = 0 # 噪声的均值\n",
    "gen_std = 1 #噪声的方差\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个生成模型，通过输入噪声来产生一张图片\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 假定输入为一张1x1xnz维的数据(nz维的向量)\n",
    "            nn.ConvTranspose2d(nz , ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 输入一个４*4*ngf*8\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 输入一个8*8*ngf*4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 输入一个16*16*ngf*2\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 输入一个32*32*ngf\n",
    "            nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # 输出一张96*96*3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    构建一个判别器，相当与一个二分类问题, 生成一个值\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # 输入96*96*3\n",
    "            nn.Conv2d(3, ndf, 5, 3, 1, bias=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            # 输入32*32*ndf\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "\n",
    "            # 输入16*16*ndf*2\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "\n",
    "            # 输入为8*8*ndf*4\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "\n",
    "            # 输入为4*4*ndf*8\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=True),\n",
    "            nn.Sigmoid()  # 分类问题\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"training NetWork\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\") if gpu else torch.device(\"cpu\")\n",
    "\n",
    "    # 1.预处理数据\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(image_size),  # 3*96*96\n",
    "        torchvision.transforms.CenterCrop(image_size),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    #  1.1 加载数据\n",
    "    dataset = torchvision.datasets.ImageFolder(data_path, transform=transforms)  # TODO 复习这个封装方法\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=num_workers,\n",
    "                            drop_last=True)  # TODO 查看drop_last操作\n",
    "\n",
    "    # 2．初始化网络\n",
    "    netg = Generator()\n",
    "    netd = Discriminator()\n",
    "    # 2.1判断网络是否已有权重数值\n",
    "    map_location = lambda storage, loc: storage  # TODO 复习map_location操作\n",
    "\n",
    "    if netg_path:\n",
    "        netg.load_state_dict(torch.load(netg_path, map_location=map_location))\n",
    "    if netd_path:\n",
    "        netd.load_state_dict(torch.load(netd_path, map_location=map_location))\n",
    "    # 2.2 搬移模型到指定设备\n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    # 3. 定义优化策略\n",
    "    #  TODO 复习Adam算法\n",
    "    optimize_g = torch.optim.Adam(netg.parameters(), lr=lr1, betas=(beta1,0.999))\n",
    "    optimize_d = torch.optim.Adam(netd.parameters(), lr=lr2, betas=(beta1, 0.999))\n",
    "    criterions = nn.BCELoss().to(device)  # TODO 重新复习BCELoss方法\n",
    "\n",
    "    # 4. 定义标签, 并且开始注入生成器的输入noise\n",
    "    true_labels = torch.ones(batch_size).to(device)\n",
    "    fake_labels = torch.zeros(batch_size).to(device)\n",
    "#     noises = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "    fix_noises = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "\n",
    "#     errord_meter = AverageValueMeter()  # TODO 重新阅读torchnet\n",
    "#     errorg_meter = AverageValueMeter()\n",
    "\n",
    "    #  6.训练网络\n",
    "    epochs = range(max_epoch)\n",
    "#     write = SummaryWriter(log_dir=virs, comment='loss')\n",
    "\n",
    "    # 6.1 设置迭代\n",
    "    for epoch in iter(epochs):\n",
    "        #  6.2 读取每一个batch 数据\n",
    "        for ii_, (img, _) in enumerate(dataloader):#tqdm.tqdm(enumerate(dataloader)):\n",
    "            real_img = img.to(device)\n",
    "\n",
    "            #  6.3开始训练生成器和判别器\n",
    "            #  注意要使得生成的训练次数小于一些\n",
    "            if ii_ % d_every == 0:\n",
    "                optimize_d.zero_grad()\n",
    "                # 训练判别器\n",
    "                # 真图\n",
    "                output = netd(real_img)\n",
    "                error_d_real = criterions(output, true_labels)\n",
    "                error_d_real.backward()\n",
    "\n",
    "                # 随机生成的假图\n",
    "                noises = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "                noises = noises.detach()\n",
    "                fake_image = netg(noises).detach()\n",
    "                output = netd(fake_image)\n",
    "                error_d_fake = criterions(output, fake_labels)\n",
    "                error_d_fake.backward()\n",
    "                optimize_d.step()\n",
    "\n",
    "                # 计算loss\n",
    "                error_d = error_d_fake + error_d_real            \n",
    "                D_losses.append(error_d.item())\n",
    "                print(\"[{}-{}]/{} Discriminator loss_real:{} loss_fake:{} loss_total:{}\".format(ii_, epoch, max_epoch, error_d_real.item(), \n",
    "                                                                                                error_d_fake.item(), error_d.item()))\n",
    "#                 errord_meter.add(error_d.item())\n",
    "\n",
    "            # 训练生成器\n",
    "            if ii_ % g_every == 0:\n",
    "                optimize_g.zero_grad()\n",
    "                noises.data.copy_(torch.randn(batch_size, nz, 1, 1))\n",
    "                fake_img = netg(noises)\n",
    "                output = netd(fake_img)\n",
    "                error_g = criterions(output, true_labels)\n",
    "                error_g.backward()\n",
    "                optimize_g.step()\n",
    "                G_losses.append(error_g.item())\n",
    "                print(\"[{}-{}]/{} Generator loss:{}\".format(ii_, epoch, max_epoch, error_g.item()))\n",
    "#                 errorg_meter.add(error_g.item())\n",
    "#             # 绘制数据\n",
    "#             if ii_ % 5 == 0:\n",
    "#                 write.add_scalar(\"Discriminator_loss\", errord_meter.value()[0])\n",
    "#                 write.add_scalar(\"Generator_loss\", errorg_meter.value()[0])\n",
    "\n",
    "        #  7.保存模型\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            with torch.no_grad():\n",
    "                fix_fake_image = netg(fix_noises).detach().cpu()\n",
    "#             fix_fake_image = netg(fix_noises)\n",
    "            torchvision.utils.save_image(fix_fake_image.data[:64], \"%s/second_%s.png\" % (\n",
    "                save_path, epoch), normalize=True)\n",
    "\n",
    "            torch.save(netd.state_dict(), 'dataset_gan/models/dcgan/netd_%s.pth' % epoch)\n",
    "            torch.save(netg.state_dict(), 'dataset_gan/models/dcgan/netg_%s.pth' % epoch)\n",
    "#             errord_meter.reset()\n",
    "#             errorg_meter.reset()\n",
    "\n",
    "#     write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate():\n",
    "    \"\"\"用训练好的数据进行生成图片\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if gpu else \"cpu\")\n",
    "\n",
    "    #  1.加载训练好权重数据\n",
    "    netg = Generator().eval()\n",
    "    netd = Discriminator().eval()\n",
    "    \n",
    "    map_location = lambda storage, loc: storage\n",
    "\n",
    "    netd.load_state_dict(torch.load(netd_path, map_location=map_location), False)\n",
    "    netg.load_state_dict(torch.load(netg_path, map_location=map_location), False)\n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    #  2.生成训练好的图片\n",
    "    noise = torch.randn(gen_search_num, nz, 1, 1).normal_(gen_mean,gen_std)\n",
    "    noise.to(device)\n",
    "\n",
    "    fake_image = netg(noise)\n",
    "    score = netd(fake_image).detach()  # TODO 查阅topk()函数\n",
    "\n",
    "    # 挑选出合适的图片\n",
    "    indexs = score.topk(gen_num)[1]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for ii in indexs:\n",
    "        result.append(fake_image.data[ii])\n",
    "\n",
    "    torchvision.utils.save_image(torch.stack(result), gen_img, normalize=True, range=(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================WGAN========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset_gan/data/' # 数据集存放路径\n",
    "num_workers = 1 # 多进程加载数据所用的进程数\n",
    "image_size = 96 # 图片尺寸\n",
    "batch_size = 128\n",
    "max_epoch =  200\n",
    "lr1 = 1e-5 # 生成器的学习率\n",
    "lr2 = 1e-5 # 判别器的学习率\n",
    "beta1=0.5 # Adam优化器的beta1参数\n",
    "gpu=False # 是否使用GPU --nogpu或者--gpu=False不使用gpu\n",
    "nz=100 # 噪声维度\n",
    "ngf = 64 # 生成器feature map数\n",
    "ndf = 64 # 判别器feature map数\n",
    "\n",
    "clamp_num = 0.01 # 判别器梯度修剪\n",
    "    \n",
    "save_path = 'dataset_gan/train_result/wgan/' #训练时生成图片保存路径\n",
    "    \n",
    "# vis = False # 是否使用visdom可视化\n",
    "# env = 'GAN' # visdom的env\n",
    "plot_every = 20 # 每间隔20 batch，visdom画图一次\n",
    "save_every = 3\n",
    "# debug_file='/tmp/debuggan' # 存在该文件则进入debug模式\n",
    "d_every=1 # 每1个batch训练一次判别器\n",
    "g_every=5 # 每5个batch训练一次生成器\n",
    "decay_every=10 # 没10个epoch保存一次模型\n",
    "netd_path = '' #预训练模型\n",
    "netg_path = ''\n",
    "    \n",
    "# 只测试不训练\n",
    "gen_img = 'result.png'\n",
    "# 从512张生成的图片中保存最好的64张\n",
    "gen_num = 64 \n",
    "gen_search_num = 512 \n",
    "gen_mean = 0 # 噪声的均值\n",
    "gen_std = 1 #噪声的方差\n",
    "G_losses = []\n",
    "D_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    定义一个生成模型，通过输入噪声来产生一张图片\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 假定输入为一张1x1xnz维的数据(nz维的向量)\n",
    "            nn.ConvTranspose2d(nz , ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 输入一个４*4*ngf*8\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 输入一个8*8*ngf*4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 输入一个16*16*ngf*2\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 输入一个32*32*ngf\n",
    "            nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # 输出一张96*96*3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    构建一个判别器，相当与一个二分类问题, 生成一个值\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # 输入96*96*3\n",
    "            nn.Conv2d(3, ndf, 5, 3, 1, bias=False),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "\n",
    "            # 输入32*32*ndf\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "\n",
    "            # 输入16*16*ndf*2\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "\n",
    "            # 输入为8*8*ndf*4\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "\n",
    "            # 输入为4*4*ndf*8\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=True),\n",
    "#             nn.Sigmoid()  # 分类问题\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    # weight_initialization: important for wgan\n",
    "    class_name = m.__class__.__name__\n",
    "    if class_name.find(\"Conv\") != -1:\n",
    "      m.weight.data.normal_(0.0, 0.02)\n",
    "    elif class_name.find(\"Norm\") != -1:\n",
    "      m.weight.data.normal_(1.0, 0.02)\n",
    "      m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"training NetWork\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\") if gpu else torch.device(\"cpu\")\n",
    "\n",
    "    # 1.预处理数据\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(image_size),  # 3*96*96\n",
    "        torchvision.transforms.CenterCrop(image_size),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    #  1.1 加载数据\n",
    "    dataset = torchvision.datasets.ImageFolder(data_path, transform=transforms)  # TODO 复习这个封装方法\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=num_workers,\n",
    "                            drop_last=True)  # TODO 查看drop_last操作\n",
    "\n",
    "    # 2．初始化网络\n",
    "    netg = Generator()\n",
    "    netd = Discriminator()\n",
    "    netg.apply(weight_init)\n",
    "    netd.apply(weight_init)\n",
    "    # 2.1判断网络是否已有权重数值\n",
    "    map_location = lambda storage, loc: storage  # TODO 复习map_location操作\n",
    "\n",
    "    if netg_path:\n",
    "        netg.load_state_dict(torch.load(netg_path, map_location=map_location))\n",
    "    if netd_path:\n",
    "        netd.load_state_dict(torch.load(netd_path, map_location=map_location))\n",
    "    # 2.2 搬移模型到指定设备\n",
    "    netd.to(device)\n",
    "    netg.to(device)\n",
    "\n",
    "    # 3. 定义优化策略\n",
    "    #  TODO 复习Adam算法\n",
    "#     optimize_g = torch.optim.Adam(netg.parameters(), lr=lr1, betas=(beta1,0.999))\n",
    "#     optimize_d = torch.optim.Adam(netd.parameters(), lr=lr2, betas=(beta1, 0.999))\n",
    "    optimizer_g = torch.optim.RMSprop(netg.parameters(),lr=lr1 ) \n",
    "    optimizer_d = torch.optim.RMSprop(netd.parameters(),lr=lr2 ) \n",
    "#     criterions = nn.BCELoss().to(device)  # TODO 重新复习BCELoss方法\n",
    "    scheduler_g = torch.optim.lr_scheduler.ExponentialLR(optimizer_g, gamma=0.99)\n",
    "    scheduler_d = torch.optim.lr_scheduler.ExponentialLR(optimizer_d, gamma=0.99)\n",
    "\n",
    "    # 4. 定义标签, 并且开始注入生成器的输入noise\n",
    "    true_labels = torch.ones(batch_size).to(device)\n",
    "    fake_labels = torch.zeros(batch_size).to(device)\n",
    "#     noises = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "    fix_noises = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "\n",
    "#     errord_meter = AverageValueMeter()  # TODO 重新阅读torchnet\n",
    "#     errorg_meter = AverageValueMeter()\n",
    "\n",
    "    #  6.训练网络\n",
    "    epochs = range(max_epoch)\n",
    "#     write = SummaryWriter(log_dir=virs, comment='loss')\n",
    "\n",
    "\n",
    "    one = torch.FloatTensor([1])\n",
    "    mone = -1 * one\n",
    "    # 6.1 设置迭代\n",
    "    for epoch in iter(epochs):\n",
    "        #  6.2 读取每一个batch 数据\n",
    "        for ii_, (img, _) in enumerate(dataloader):#tqdm.tqdm(enumerate(dataloader)):\n",
    "            real_img = img.to(device)\n",
    "\n",
    "            #  6.3开始训练生成器和判别器\n",
    "            #  注意要使得生成的训练次数小于一些\n",
    "            if ii_ % d_every == 0:\n",
    "                for param in netd.parameters():\n",
    "                    param.requires_grad = True\n",
    "                optimizer_d.zero_grad()\n",
    "                # 训练判别器\n",
    "                # 真图\n",
    "                output = netd(real_img)\n",
    "                error_d_real = output.mean(0).view(1)\n",
    "                error_d_real.backward(one)\n",
    "\n",
    "                # 随机生成的假图\n",
    "                noises = torch.randn(batch_size, nz, 1, 1)\n",
    "#                 noises = noises.detach()\n",
    "                fake_image = netg(noises).detach()\n",
    "                output = netd(fake_image)\n",
    "                error_d_fake = output.mean(0).view(1)\n",
    "                error_d_fake.backward(mone)\n",
    "                optimizer_d.step()\n",
    "#                 scheduler_d.step()\n",
    "\n",
    "                # 计算loss\n",
    "                error_d = error_d_fake - error_d_real      \n",
    "                for parm in netd.parameters():\n",
    "                    parm.data.clamp_(-clamp_num, clamp_num)\n",
    "                D_losses.append(error_d.item())\n",
    "                print(\"[{}-{}]/{} Discriminator loss_real:{} loss_fake:{} loss_total:{}\".format(ii_, epoch, max_epoch, error_d_real.item(), \n",
    "                                                                                                error_d_fake.item(), error_d.item()))\n",
    "\n",
    "            # 训练生成器\n",
    "            if ii_ % g_every == 0:\n",
    "                for param in netd.parameters():\n",
    "                    param.requires_grad = False\n",
    "                optimizer_g.zero_grad()\n",
    "                noises.data.copy_(torch.randn(batch_size, nz, 1, 1))\n",
    "                fake_img = netg(noises)\n",
    "                output = netd(fake_img)\n",
    "#                 error_g = torch.mean(output).view(1)\n",
    "                error_g.backward(one)\n",
    "                optimizer_g.step()\n",
    "#                 scheduler_g.step()\n",
    "                G_losses.append(error_g.item())\n",
    "                print(\"[{}-{}]/{} Generator loss:{}\".format(ii_, epoch, max_epoch, error_g.item()))\n",
    "\n",
    "        #  7.保存模型\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            with torch.no_grad():\n",
    "                fix_fake_image = netg(fix_noises).detach().cpu()\n",
    "            torchvision.utils.save_image(fix_fake_image.data[:64], \"%s/%s.png\" % (\n",
    "                save_path, epoch), normalize=True)\n",
    "\n",
    "            torch.save(netd.state_dict(), 'dataset_gan/models/wgan/netd_%s.pth' % epoch)\n",
    "            torch.save(netg.state_dict(), 'dataset_gan/models/wgan/netg_%s.pth' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def image_show(image):\n",
    "#     image = image.squeeze(0)\n",
    "    img = np.array(image).transpose((1,2,0))\n",
    "    mean = np.array((0.5, 0.5, 0.5))\n",
    "    std = np.array((0.5, 0.5, 0.5))\n",
    "    img = img*std + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if gpu else \"cpu\")\n",
    "\n",
    "#  1.加载训练好权重数据\n",
    "netg = Generator().eval()\n",
    "netd = Discriminator().eval()\n",
    "    \n",
    "map_location = lambda storage, loc: storage\n",
    "netd_path = \"dataset_gan/models/wgan/beauty1/netd_111.pth\"\n",
    "netg_path = \"dataset_gan/models/wgan/beauty1/netg_111.pth\"\n",
    "netd.load_state_dict(torch.load(netd_path, map_location=map_location), False)\n",
    "netg.load_state_dict(torch.load(netg_path, map_location=map_location), False)\n",
    "netd.to(device)\n",
    "netg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate():\n",
    "    \"\"\"用训练好的数据进行生成图片\"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    #  2.生成训练好的图片\n",
    "    noise = torch.randn(gen_search_num, nz, 1, 1).normal_(gen_mean,gen_std)\n",
    "    noise.to(device)\n",
    "\n",
    "    fake_image = netg(noise)\n",
    "    score = netd(fake_image).detach()  # TODO 查阅topk()函数\n",
    "\n",
    "    # 挑选出合适的图片\n",
    "    indexs = score.topk(gen_num)[1]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for ii in indexs:\n",
    "        result.append(fake_image.data[ii])\n",
    "\n",
    "#     image_show(result)\n",
    "    torchvision.utils.save_image(torch.stack(result), gen_img, normalize=True, range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
