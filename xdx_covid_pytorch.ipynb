{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models, transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, file_path, label_dict, transform = None):\n",
    "        self.images = list(paths.list_images(file_path))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = np.asarray(image)\n",
    "            image = torch.from_numpy(image)\n",
    "            \n",
    "        label = label_dict[self.images[index].split(\"/\")[2]]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 图像的均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mean = (0.4914, 0.4822, 0.4465)\n",
    "image_std = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "#     transforms.RandomResizedCrop(224),  #把图像裁剪成270*270\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
    "    #ransforms.RandomRotation((-45,45)), #随机旋转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(image_mean, image_std), #R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "transform_val = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),  #把图像裁剪成270*270\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(image_mean, image_std), #R,G,B每层的归一化用到的均值和方差\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\"train\": transform_train, \"val\": transform_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\"crosswalk\":0, \"grass\":1, \"house\":2, \"red\":3, \"yellow\":4, \"green\": 5, \"turn_left\":6, \"turn_right\":7, \"stop\":8}\n",
    "mydata = {x: MyDataSet(os.path.join(\"dataset-pytorch\", x), label_dict, data_transforms[x]) for x in (\"train\", \"val\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 7559, 'val': 836}\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(mydata[x]) for x in (\"train\", \"val\")}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_show(image):\n",
    "    img = image.numpy().transpose((1,2,0))\n",
    "    mean = np.array(image_mean)\n",
    "    std = np.array(image_std)\n",
    "    img = img*std + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "image, label = mydata[\"train\"][0]\n",
    "print(image.shape, type(image))\n",
    "# image_show = transforms.ToPILImage()(image)\n",
    "image_show(image)\n",
    "# plt.imshow(image_show)\n",
    "# plt.show()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用torch封装的ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myimages = ImageFolder('dataset', transform=transform)\n",
    "# print(myimages.class_to_idx)\n",
    "# print(myimages[0][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size(每个batch的大小)、 shuffle(是否进行shuffle操作)、 num_workers(加载数据的时候使用几个子进程)\n",
    "dataloaders = {x:DataLoader(mydata[x], batch_size=64, shuffle=True, num_workers=0) for x in (\"train\", \"val\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for index, data in enumerate(dataloaders[\"train\"]):\n",
    "    print(index, data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 8, 2, 8, 8, 8, 4, 5, 3, 5, 4, 3, 8, 2, 5, 7, 2, 4, 3, 6, 5, 5, 3, 4,\n",
      "        2, 5, 2, 3, 3, 8, 3, 4, 3, 4, 6, 3, 3, 2, 3, 6, 6, 2, 2, 2, 3, 5, 8, 2,\n",
      "        3, 3, 5, 4, 3, 5, 3, 4, 2, 5, 4, 2, 5, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for data, label in dataloaders[\"train\"]:\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==============分割线===============**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True) # 这里自动下载官方的预训练模型，并且将所有的参数层进行冻结\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "# print(model_ft.fc)\n",
    "num_fc_ftr = model_ft.fc.in_features #获取到fc层的输入\n",
    "model_ft.fc = nn.Linear(num_fc_ftr, 9) # 定义一个新的FC层\n",
    "# print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载vgg16模型\n",
    "model_vgg = torchvision.models.vgg16(pretrained=False) #我们不下载预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, fc_number1, fc_number2, output_number):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # 修改\n",
    "#             nn.MaxPool2d(4),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(512*7*7, fc_number1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_number1, fc_number2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fc_number2, output_number),\n",
    "            nn.Softmax(dim=1)\n",
    "#             nn.Linear(512*1*1, fc_number1),\n",
    "#             nn.ELU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(fc_number1, fc_number2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(fc_number1, output_number),\n",
    "#             nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyModel(4096,512,9)\n",
    "# mymodel = MyModel(64,0,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"success\">写法1</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, epochs = 25):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch: {}/{}\".format(epoch, epochs))\n",
    "        print(\"*\"*10)\n",
    "        for phase in (\"train\", \"val\"):\n",
    "            if \"train\" == phase:\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for i, data in enumerate(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(\"train\" == phase):\n",
    "                    outputs = model(inputs)\n",
    "                    _, predict = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    print(\"[{}, {}] loss: {}\".format(epoch, i, loss.item()))\n",
    "                \n",
    "                    if \"train\" == phase:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(predict == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print(\"{} loss: {}, Acc:{}\".format(epoch, epoch_loss, epoch_acc))\n",
    "            if \"train\" == phase:      \n",
    "                writer.add_scalar(\"train/loss\", epoch_loss, epoch)\n",
    "                writer.add_scalar(\"train/acc\", epoch_acc, epoch)\n",
    "            else:\n",
    "                writer.add_scalar(\"val/loss\", epoch_loss, epoch)\n",
    "                writer.add_scalar(\"val/acc\", epoch_acc, epoch)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "    writer.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(mymodel.parameters(), lr=0.1)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params':mymodel.parameters()}\n",
    "# ], lr=0.001)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_ft.fc.parameters()}\n",
    "], lr=0.001)#指定 新加的fc层的学习率\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = train_model(model_ft, criterion, optimizer, exp_lr_scheduler, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"success\">写法2</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, device, train_loader, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        x,y= data\n",
    "#         x=x.to(device)\n",
    "#         y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat= model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"{}/{} loss:{}\".format(batch_idx+1, epoch, loss.item()))\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}'.format(epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, optimizer, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "#             x=x.to(device)\n",
    "#             y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss += criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\"i:\",i)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(mydata[\"val\"]),\n",
    "        100. * correct / len(mydata[\"val\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 loss:0.08356035500764847\n",
      "2/1 loss:0.08454636484384537\n",
      "3/1 loss:0.035955946892499924\n",
      "4/1 loss:0.06775876134634018\n",
      "5/1 loss:0.12060993164777756\n",
      "6/1 loss:0.14953844249248505\n",
      "7/1 loss:0.04605880379676819\n",
      "8/1 loss:0.08476293087005615\n",
      "9/1 loss:0.08932047337293625\n",
      "10/1 loss:0.16721434891223907\n",
      "11/1 loss:0.08561715483665466\n",
      "12/1 loss:0.1381785273551941\n",
      "13/1 loss:0.19414521753787994\n",
      "14/1 loss:0.1278700977563858\n",
      "15/1 loss:0.12747187912464142\n",
      "16/1 loss:0.1349407285451889\n",
      "17/1 loss:0.1165177971124649\n",
      "18/1 loss:0.11174941062927246\n",
      "19/1 loss:0.15495403110980988\n",
      "20/1 loss:0.09356105327606201\n",
      "21/1 loss:0.18851542472839355\n",
      "22/1 loss:0.06869810819625854\n",
      "23/1 loss:0.18884921073913574\n",
      "24/1 loss:0.11995755881071091\n",
      "25/1 loss:0.0811598151922226\n",
      "26/1 loss:0.14018647372722626\n",
      "27/1 loss:0.13444656133651733\n",
      "28/1 loss:0.035941772162914276\n",
      "29/1 loss:0.09877565503120422\n",
      "30/1 loss:0.08111817389726639\n",
      "31/1 loss:0.035380393266677856\n",
      "32/1 loss:0.09680740535259247\n",
      "33/1 loss:0.14813339710235596\n",
      "34/1 loss:0.14442357420921326\n",
      "35/1 loss:0.15327158570289612\n",
      "36/1 loss:0.11537837982177734\n",
      "37/1 loss:0.16079336404800415\n",
      "38/1 loss:0.08839985728263855\n",
      "39/1 loss:0.09409360587596893\n",
      "40/1 loss:0.10297971218824387\n",
      "41/1 loss:0.12157902866601944\n",
      "42/1 loss:0.096735879778862\n",
      "43/1 loss:0.17259904742240906\n",
      "44/1 loss:0.13419024646282196\n",
      "45/1 loss:0.17709122598171234\n",
      "46/1 loss:0.08460849523544312\n",
      "47/1 loss:0.0700819119811058\n",
      "48/1 loss:0.14290444552898407\n",
      "49/1 loss:0.10951130837202072\n",
      "50/1 loss:0.06344998627901077\n",
      "51/1 loss:0.11219259351491928\n",
      "52/1 loss:0.08662909269332886\n",
      "53/1 loss:0.08550424873828888\n",
      "54/1 loss:0.08533485978841782\n",
      "55/1 loss:0.15196740627288818\n",
      "56/1 loss:0.08599568903446198\n",
      "57/1 loss:0.15470518171787262\n",
      "58/1 loss:0.051334448158741\n",
      "59/1 loss:0.04829762130975723\n",
      "60/1 loss:0.12482345849275589\n",
      "61/1 loss:0.24540573358535767\n",
      "62/1 loss:0.08329050987958908\n",
      "63/1 loss:0.09954553842544556\n",
      "64/1 loss:0.044338807463645935\n",
      "65/1 loss:0.27132126688957214\n",
      "66/1 loss:0.10628490895032883\n",
      "67/1 loss:0.11240043491125107\n",
      "68/1 loss:0.12378492951393127\n",
      "69/1 loss:0.11947087198495865\n",
      "70/1 loss:0.14711341261863708\n",
      "71/1 loss:0.07516546547412872\n",
      "72/1 loss:0.06519253551959991\n",
      "73/1 loss:0.09442540258169174\n",
      "74/1 loss:0.07579407095909119\n",
      "75/1 loss:0.06095607206225395\n",
      "76/1 loss:0.11622268706560135\n",
      "77/1 loss:0.11777892708778381\n",
      "78/1 loss:0.0434759184718132\n",
      "79/1 loss:0.10757138580083847\n",
      "80/1 loss:0.11809659004211426\n",
      "81/1 loss:0.14501766860485077\n",
      "82/1 loss:0.08024154603481293\n",
      "83/1 loss:0.22041869163513184\n",
      "84/1 loss:0.09704361855983734\n",
      "85/1 loss:0.11517205834388733\n",
      "86/1 loss:0.13557709753513336\n",
      "87/1 loss:0.20096760988235474\n",
      "88/1 loss:0.06334390491247177\n",
      "89/1 loss:0.17796364426612854\n",
      "90/1 loss:0.0799037367105484\n",
      "91/1 loss:0.10373154282569885\n",
      "92/1 loss:0.1665334701538086\n",
      "93/1 loss:0.09316705167293549\n",
      "94/1 loss:0.09343598783016205\n",
      "95/1 loss:0.0945955216884613\n",
      "96/1 loss:0.1126643642783165\n",
      "97/1 loss:0.11200908571481705\n",
      "98/1 loss:0.13363318145275116\n",
      "99/1 loss:0.11258473247289658\n",
      "100/1 loss:0.21460303664207458\n",
      "101/1 loss:0.12513954937458038\n",
      "102/1 loss:0.04908706247806549\n",
      "103/1 loss:0.08364894241094589\n",
      "104/1 loss:0.16995935142040253\n",
      "105/1 loss:0.18464434146881104\n",
      "106/1 loss:0.16552022099494934\n",
      "107/1 loss:0.12711355090141296\n",
      "108/1 loss:0.0958235040307045\n",
      "109/1 loss:0.15971159934997559\n",
      "110/1 loss:0.10070730745792389\n",
      "111/1 loss:0.17630963027477264\n",
      "112/1 loss:0.06778187304735184\n",
      "113/1 loss:0.12767945230007172\n",
      "114/1 loss:0.10742015391588211\n",
      "115/1 loss:0.20458240807056427\n",
      "116/1 loss:0.11478863656520844\n",
      "117/1 loss:0.15762415528297424\n",
      "118/1 loss:0.04543270543217659\n",
      "119/1 loss:0.10071349143981934\n",
      "Train Epoch: 1\t Loss: 0.100713\n",
      "CPU times: user 37min 49s, sys: 6min 37s, total: 44min 27s\n",
      "Wall time: 5min 53s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 795/836 (95%)\n",
      "\n",
      "1/2 loss:0.1823873668909073\n",
      "2/2 loss:0.23414666950702667\n",
      "3/2 loss:0.1393490731716156\n",
      "4/2 loss:0.1231977641582489\n",
      "5/2 loss:0.12641260027885437\n",
      "6/2 loss:0.15431447327136993\n",
      "7/2 loss:0.10483279824256897\n",
      "8/2 loss:0.13739028573036194\n",
      "9/2 loss:0.15426494181156158\n",
      "10/2 loss:0.1205429807305336\n",
      "11/2 loss:0.12494959682226181\n",
      "12/2 loss:0.08526135981082916\n",
      "13/2 loss:0.06661301106214523\n",
      "14/2 loss:0.08662167191505432\n",
      "15/2 loss:0.10921547561883926\n",
      "16/2 loss:0.11677968502044678\n",
      "17/2 loss:0.09933177381753922\n",
      "18/2 loss:0.07119511067867279\n",
      "19/2 loss:0.12563632428646088\n",
      "20/2 loss:0.09821724146604538\n",
      "21/2 loss:0.13822445273399353\n",
      "22/2 loss:0.08452527970075607\n",
      "23/2 loss:0.07981103658676147\n",
      "24/2 loss:0.095709428191185\n",
      "25/2 loss:0.26429587602615356\n",
      "26/2 loss:0.12277866899967194\n",
      "27/2 loss:0.09015318006277084\n",
      "28/2 loss:0.11598649621009827\n",
      "29/2 loss:0.060290344059467316\n",
      "30/2 loss:0.1444174349308014\n",
      "31/2 loss:0.12023486942052841\n",
      "32/2 loss:0.04795036464929581\n",
      "33/2 loss:0.05664748325943947\n",
      "34/2 loss:0.08431978523731232\n",
      "35/2 loss:0.1873527616262436\n",
      "36/2 loss:0.14094872772693634\n",
      "37/2 loss:0.04650396481156349\n",
      "38/2 loss:0.1469508707523346\n",
      "39/2 loss:0.058647118508815765\n",
      "40/2 loss:0.10431194305419922\n",
      "41/2 loss:0.0952553004026413\n",
      "42/2 loss:0.17540307343006134\n",
      "43/2 loss:0.05571727082133293\n",
      "44/2 loss:0.03920435160398483\n",
      "45/2 loss:0.0780864730477333\n",
      "46/2 loss:0.1184522733092308\n",
      "47/2 loss:0.0996972918510437\n",
      "48/2 loss:0.11130670458078384\n",
      "49/2 loss:0.1182195320725441\n",
      "50/2 loss:0.0947016030550003\n",
      "51/2 loss:0.13232876360416412\n",
      "52/2 loss:0.06365874409675598\n",
      "53/2 loss:0.0996713787317276\n",
      "54/2 loss:0.15755251049995422\n",
      "55/2 loss:0.050639841705560684\n",
      "56/2 loss:0.08323483169078827\n",
      "57/2 loss:0.11047715693712234\n",
      "58/2 loss:0.20297907292842865\n",
      "59/2 loss:0.1360158622264862\n",
      "60/2 loss:0.10663320869207382\n",
      "61/2 loss:0.22774182260036469\n",
      "62/2 loss:0.1489827036857605\n",
      "63/2 loss:0.2152176946401596\n",
      "64/2 loss:0.08362715691328049\n",
      "65/2 loss:0.14041456580162048\n",
      "66/2 loss:0.13573786616325378\n",
      "67/2 loss:0.22544851899147034\n",
      "68/2 loss:0.27474620938301086\n",
      "69/2 loss:0.1250467598438263\n",
      "70/2 loss:0.21380338072776794\n",
      "71/2 loss:0.05250430852174759\n",
      "72/2 loss:0.05417985841631889\n",
      "73/2 loss:0.09521180391311646\n",
      "74/2 loss:0.08595683425664902\n",
      "75/2 loss:0.13421832025051117\n",
      "76/2 loss:0.14239297807216644\n",
      "77/2 loss:0.09014412015676498\n",
      "78/2 loss:0.10360822826623917\n",
      "79/2 loss:0.1755519062280655\n",
      "80/2 loss:0.0971236452460289\n",
      "81/2 loss:0.1446523517370224\n",
      "82/2 loss:0.11682093888521194\n",
      "83/2 loss:0.08073922991752625\n",
      "84/2 loss:0.17301107943058014\n",
      "85/2 loss:0.12233106791973114\n",
      "86/2 loss:0.059397682547569275\n",
      "87/2 loss:0.22331184148788452\n",
      "88/2 loss:0.14335638284683228\n",
      "89/2 loss:0.07983248680830002\n",
      "90/2 loss:0.11310001462697983\n",
      "91/2 loss:0.04963933676481247\n",
      "92/2 loss:0.08629384636878967\n",
      "93/2 loss:0.08174010366201401\n",
      "94/2 loss:0.11462228000164032\n",
      "95/2 loss:0.1001005470752716\n",
      "96/2 loss:0.11445224285125732\n",
      "97/2 loss:0.12452760338783264\n",
      "98/2 loss:0.1397349089384079\n",
      "99/2 loss:0.06293127685785294\n",
      "100/2 loss:0.09173846244812012\n",
      "101/2 loss:0.09954437613487244\n",
      "102/2 loss:0.062741719186306\n",
      "103/2 loss:0.08864129334688187\n",
      "104/2 loss:0.10607294738292694\n",
      "105/2 loss:0.16129593551158905\n",
      "106/2 loss:0.09959366917610168\n",
      "107/2 loss:0.19070540368556976\n",
      "108/2 loss:0.12095034122467041\n",
      "109/2 loss:0.08727573603391647\n",
      "110/2 loss:0.11554837971925735\n",
      "111/2 loss:0.08460170775651932\n",
      "112/2 loss:0.09965280443429947\n",
      "113/2 loss:0.11979854851961136\n",
      "114/2 loss:0.11992105096578598\n",
      "115/2 loss:0.057651132345199585\n",
      "116/2 loss:0.1470538228750229\n",
      "117/2 loss:0.17659249901771545\n",
      "118/2 loss:0.21371571719646454\n",
      "119/2 loss:0.33466655015945435\n",
      "Train Epoch: 2\t Loss: 0.334667\n",
      "CPU times: user 38min 23s, sys: 6min 57s, total: 45min 21s\n",
      "Wall time: 6min 1s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 806/836 (96%)\n",
      "\n",
      "1/3 loss:0.1308378279209137\n",
      "2/3 loss:0.11863652616739273\n",
      "3/3 loss:0.12196103483438492\n",
      "4/3 loss:0.14230456948280334\n",
      "5/3 loss:0.17543350160121918\n",
      "6/3 loss:0.06352155655622482\n",
      "7/3 loss:0.12470103055238724\n",
      "8/3 loss:0.21296659111976624\n",
      "9/3 loss:0.13045160472393036\n",
      "10/3 loss:0.19482754170894623\n",
      "11/3 loss:0.13279186189174652\n",
      "12/3 loss:0.08419010043144226\n",
      "13/3 loss:0.1181371882557869\n",
      "14/3 loss:0.13503482937812805\n",
      "15/3 loss:0.2427850365638733\n",
      "16/3 loss:0.19710317254066467\n",
      "17/3 loss:0.17344523966312408\n",
      "18/3 loss:0.06553919613361359\n",
      "19/3 loss:0.1487545520067215\n",
      "20/3 loss:0.10669761896133423\n",
      "21/3 loss:0.05112338811159134\n",
      "22/3 loss:0.20259933173656464\n",
      "23/3 loss:0.043941255658864975\n",
      "24/3 loss:0.07713798433542252\n",
      "25/3 loss:0.09276571869850159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/3 loss:0.09602949768304825\n",
      "27/3 loss:0.12458694726228714\n",
      "28/3 loss:0.16460387408733368\n",
      "29/3 loss:0.11173471808433533\n",
      "30/3 loss:0.07257960736751556\n",
      "31/3 loss:0.0818428099155426\n",
      "32/3 loss:0.10716318339109421\n",
      "33/3 loss:0.15282583236694336\n",
      "34/3 loss:0.22274214029312134\n",
      "35/3 loss:0.06885027885437012\n",
      "36/3 loss:0.1083870604634285\n",
      "37/3 loss:0.06914004683494568\n",
      "38/3 loss:0.13831321895122528\n",
      "39/3 loss:0.1001361533999443\n",
      "40/3 loss:0.0628284439444542\n",
      "41/3 loss:0.1673114001750946\n",
      "42/3 loss:0.10919841378927231\n",
      "43/3 loss:0.044509753584861755\n",
      "44/3 loss:0.062064316123723984\n",
      "45/3 loss:0.10814166814088821\n",
      "46/3 loss:0.0889834389090538\n",
      "47/3 loss:0.06199854239821434\n",
      "48/3 loss:0.13196060061454773\n",
      "49/3 loss:0.13529258966445923\n",
      "50/3 loss:0.1005946695804596\n",
      "51/3 loss:0.1380983591079712\n",
      "52/3 loss:0.15933147072792053\n",
      "53/3 loss:0.07559388130903244\n",
      "54/3 loss:0.17241595685482025\n",
      "55/3 loss:0.07688213884830475\n",
      "56/3 loss:0.11896627396345139\n",
      "57/3 loss:0.058976758271455765\n",
      "58/3 loss:0.09990045428276062\n",
      "59/3 loss:0.08574693650007248\n",
      "60/3 loss:0.09238183498382568\n",
      "61/3 loss:0.03984401747584343\n",
      "62/3 loss:0.08643229305744171\n",
      "63/3 loss:0.0480167381465435\n",
      "64/3 loss:0.11082566529512405\n",
      "65/3 loss:0.11289174109697342\n",
      "66/3 loss:0.11826767027378082\n",
      "67/3 loss:0.037818167358636856\n",
      "68/3 loss:0.09385132789611816\n",
      "69/3 loss:0.0609661303460598\n",
      "70/3 loss:0.09107798337936401\n",
      "71/3 loss:0.06806930899620056\n",
      "72/3 loss:0.19642317295074463\n",
      "73/3 loss:0.14683829247951508\n",
      "74/3 loss:0.09829555451869965\n",
      "75/3 loss:0.072255440056324\n",
      "76/3 loss:0.09171920269727707\n",
      "77/3 loss:0.06206578016281128\n",
      "78/3 loss:0.19113002717494965\n",
      "79/3 loss:0.168631449341774\n",
      "80/3 loss:0.0638745054602623\n",
      "81/3 loss:0.08242743462324142\n",
      "82/3 loss:0.14807064831256866\n",
      "83/3 loss:0.07461951673030853\n",
      "84/3 loss:0.096975177526474\n",
      "85/3 loss:0.1252000629901886\n",
      "86/3 loss:0.08401195704936981\n",
      "87/3 loss:0.10199287533760071\n",
      "88/3 loss:0.10993029922246933\n",
      "89/3 loss:0.06562183052301407\n",
      "90/3 loss:0.15805169939994812\n",
      "91/3 loss:0.0738905817270279\n",
      "92/3 loss:0.13313694298267365\n",
      "93/3 loss:0.12700285017490387\n",
      "94/3 loss:0.17595553398132324\n",
      "95/3 loss:0.06187855079770088\n",
      "96/3 loss:0.2584615647792816\n",
      "97/3 loss:0.09614093601703644\n",
      "98/3 loss:0.11099358648061752\n",
      "99/3 loss:0.12863998115062714\n",
      "100/3 loss:0.12256094813346863\n",
      "101/3 loss:0.04486766830086708\n",
      "102/3 loss:0.18938061594963074\n",
      "103/3 loss:0.07633781433105469\n",
      "104/3 loss:0.1647110879421234\n",
      "105/3 loss:0.11485830694437027\n",
      "106/3 loss:0.16352160274982452\n",
      "107/3 loss:0.22524486482143402\n",
      "108/3 loss:0.09377771615982056\n",
      "109/3 loss:0.12159794569015503\n",
      "110/3 loss:0.09242693334817886\n",
      "111/3 loss:0.13059960305690765\n",
      "112/3 loss:0.07531667500734329\n",
      "113/3 loss:0.1629379242658615\n",
      "114/3 loss:0.13798752427101135\n",
      "115/3 loss:0.146541029214859\n",
      "116/3 loss:0.05390927195549011\n",
      "117/3 loss:0.06337666511535645\n",
      "118/3 loss:0.04654276743531227\n",
      "119/3 loss:0.3682943284511566\n",
      "Train Epoch: 3\t Loss: 0.368294\n",
      "CPU times: user 38min 22s, sys: 6min 54s, total: 45min 16s\n",
      "Wall time: 6min\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 792/836 (95%)\n",
      "\n",
      "1/4 loss:0.21989049017429352\n",
      "2/4 loss:0.0824705958366394\n",
      "3/4 loss:0.09151838719844818\n",
      "4/4 loss:0.10323537886142731\n",
      "5/4 loss:0.23083721101284027\n",
      "6/4 loss:0.12030958384275436\n",
      "7/4 loss:0.07599784433841705\n",
      "8/4 loss:0.05612858384847641\n",
      "9/4 loss:0.10090547055006027\n",
      "10/4 loss:0.08588335663080215\n",
      "11/4 loss:0.11399725079536438\n",
      "12/4 loss:0.05127139016985893\n",
      "13/4 loss:0.07976093143224716\n",
      "14/4 loss:0.07906081527471542\n",
      "15/4 loss:0.14242370426654816\n",
      "16/4 loss:0.11831034719944\n",
      "17/4 loss:0.09093153476715088\n",
      "18/4 loss:0.20898671448230743\n",
      "19/4 loss:0.09526847302913666\n",
      "20/4 loss:0.16438208520412445\n",
      "21/4 loss:0.0750596672296524\n",
      "22/4 loss:0.07830255478620529\n",
      "23/4 loss:0.0910666361451149\n",
      "24/4 loss:0.05420061573386192\n",
      "25/4 loss:0.08519082516431808\n",
      "26/4 loss:0.08388808369636536\n",
      "27/4 loss:0.13867104053497314\n",
      "28/4 loss:0.10571339726448059\n",
      "29/4 loss:0.22477947175502777\n",
      "30/4 loss:0.1330617368221283\n",
      "31/4 loss:0.09717579931020737\n",
      "32/4 loss:0.08456701040267944\n",
      "33/4 loss:0.1259194016456604\n",
      "34/4 loss:0.0993419960141182\n",
      "35/4 loss:0.09402155876159668\n",
      "36/4 loss:0.0951298177242279\n",
      "37/4 loss:0.15829657018184662\n",
      "38/4 loss:0.16247940063476562\n",
      "39/4 loss:0.11398445814847946\n",
      "40/4 loss:0.02571205422282219\n",
      "41/4 loss:0.07088989019393921\n",
      "42/4 loss:0.05103302001953125\n",
      "43/4 loss:0.1141466423869133\n",
      "44/4 loss:0.1982451230287552\n",
      "45/4 loss:0.10378588736057281\n",
      "46/4 loss:0.10133152455091476\n",
      "47/4 loss:0.08438601344823837\n",
      "48/4 loss:0.06545992195606232\n",
      "49/4 loss:0.12320342659950256\n",
      "50/4 loss:0.060515034943819046\n",
      "51/4 loss:0.20391201972961426\n",
      "52/4 loss:0.07755386084318161\n",
      "53/4 loss:0.10547717660665512\n",
      "54/4 loss:0.1711956411600113\n",
      "55/4 loss:0.16055209934711456\n",
      "56/4 loss:0.1388341337442398\n",
      "57/4 loss:0.10493182390928268\n",
      "58/4 loss:0.10859903693199158\n",
      "59/4 loss:0.10172751545906067\n",
      "60/4 loss:0.11484003067016602\n",
      "61/4 loss:0.1301228404045105\n",
      "62/4 loss:0.09703706204891205\n",
      "63/4 loss:0.05346270278096199\n",
      "64/4 loss:0.20674122869968414\n",
      "65/4 loss:0.1266985833644867\n",
      "66/4 loss:0.105449378490448\n",
      "67/4 loss:0.15164080262184143\n",
      "68/4 loss:0.10656657814979553\n",
      "69/4 loss:0.2317516803741455\n",
      "70/4 loss:0.07119452953338623\n",
      "71/4 loss:0.18351668119430542\n",
      "72/4 loss:0.06460359692573547\n",
      "73/4 loss:0.057247843593358994\n",
      "74/4 loss:0.051530610769987106\n",
      "75/4 loss:0.0713360458612442\n",
      "76/4 loss:0.10170230269432068\n",
      "77/4 loss:0.050837643444538116\n",
      "78/4 loss:0.13517683744430542\n",
      "79/4 loss:0.12234814465045929\n",
      "80/4 loss:0.06804554164409637\n",
      "81/4 loss:0.13936938345432281\n",
      "82/4 loss:0.14241939783096313\n",
      "83/4 loss:0.12408348172903061\n",
      "84/4 loss:0.0678461492061615\n",
      "85/4 loss:0.12232308089733124\n",
      "86/4 loss:0.09232490509748459\n",
      "87/4 loss:0.03513343259692192\n",
      "88/4 loss:0.08276233077049255\n",
      "89/4 loss:0.06837058812379837\n",
      "90/4 loss:0.061594098806381226\n",
      "91/4 loss:0.11762674897909164\n",
      "92/4 loss:0.08073455095291138\n",
      "93/4 loss:0.11013379693031311\n",
      "94/4 loss:0.15079468488693237\n",
      "95/4 loss:0.20423366129398346\n",
      "96/4 loss:0.25018250942230225\n",
      "97/4 loss:0.12802453339099884\n",
      "98/4 loss:0.10767171531915665\n",
      "99/4 loss:0.055561866611242294\n",
      "100/4 loss:0.14999045431613922\n",
      "101/4 loss:0.10749154537916183\n",
      "102/4 loss:0.04951978847384453\n",
      "103/4 loss:0.07015416771173477\n",
      "104/4 loss:0.10164792835712433\n",
      "105/4 loss:0.08984538912773132\n",
      "106/4 loss:0.15611910820007324\n",
      "107/4 loss:0.09845121949911118\n",
      "108/4 loss:0.048222631216049194\n",
      "109/4 loss:0.09342821687459946\n",
      "110/4 loss:0.12904393672943115\n",
      "111/4 loss:0.08859029412269592\n",
      "112/4 loss:0.1260928362607956\n",
      "113/4 loss:0.2271917462348938\n",
      "114/4 loss:0.11824358999729156\n",
      "115/4 loss:0.20378105342388153\n",
      "116/4 loss:0.15142834186553955\n",
      "117/4 loss:0.066915363073349\n",
      "118/4 loss:0.10096270591020584\n",
      "119/4 loss:0.6166060566902161\n",
      "Train Epoch: 4\t Loss: 0.616606\n",
      "CPU times: user 38min 33s, sys: 6min 53s, total: 45min 27s\n",
      "Wall time: 6min 2s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 799/836 (96%)\n",
      "\n",
      "1/5 loss:0.18974140286445618\n",
      "2/5 loss:0.1376473605632782\n",
      "3/5 loss:0.17442218959331512\n",
      "4/5 loss:0.1652076244354248\n",
      "5/5 loss:0.3062954246997833\n",
      "6/5 loss:0.07224489003419876\n",
      "7/5 loss:0.10737527161836624\n",
      "8/5 loss:0.13742512464523315\n",
      "9/5 loss:0.21401572227478027\n",
      "10/5 loss:0.07885608077049255\n",
      "11/5 loss:0.09907450526952744\n",
      "12/5 loss:0.15603220462799072\n",
      "13/5 loss:0.10538606345653534\n",
      "14/5 loss:0.16107355058193207\n",
      "15/5 loss:0.06134422868490219\n",
      "16/5 loss:0.13442449271678925\n",
      "17/5 loss:0.11710110306739807\n",
      "18/5 loss:0.045448433607816696\n",
      "19/5 loss:0.0752558633685112\n",
      "20/5 loss:0.1180274486541748\n",
      "21/5 loss:0.06295159459114075\n",
      "22/5 loss:0.11395733058452606\n",
      "23/5 loss:0.09667479246854782\n",
      "24/5 loss:0.1310432106256485\n",
      "25/5 loss:0.12328355759382248\n",
      "26/5 loss:0.14058612287044525\n",
      "27/5 loss:0.058675866574048996\n",
      "28/5 loss:0.13280954957008362\n",
      "29/5 loss:0.06924130767583847\n",
      "30/5 loss:0.1599300503730774\n",
      "31/5 loss:0.11464352905750275\n",
      "32/5 loss:0.12439880520105362\n",
      "33/5 loss:0.05391145125031471\n",
      "34/5 loss:0.12039440125226974\n",
      "35/5 loss:0.11913632601499557\n",
      "36/5 loss:0.09619531035423279\n",
      "37/5 loss:0.0928734615445137\n",
      "38/5 loss:0.11835577338933945\n",
      "39/5 loss:0.1752753108739853\n",
      "40/5 loss:0.08445246517658234\n",
      "41/5 loss:0.16990438103675842\n",
      "42/5 loss:0.054613448679447174\n",
      "43/5 loss:0.05594664439558983\n",
      "44/5 loss:0.07144909352064133\n",
      "45/5 loss:0.07893938571214676\n",
      "46/5 loss:0.0811486691236496\n",
      "47/5 loss:0.17643731832504272\n",
      "48/5 loss:0.13904345035552979\n",
      "49/5 loss:0.14895136654376984\n",
      "50/5 loss:0.10058562457561493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/5 loss:0.15638403594493866\n",
      "52/5 loss:0.11773905903100967\n",
      "53/5 loss:0.16214245557785034\n",
      "54/5 loss:0.048874907195568085\n",
      "55/5 loss:0.11025037616491318\n",
      "56/5 loss:0.08982797712087631\n",
      "57/5 loss:0.07284475117921829\n",
      "58/5 loss:0.07699272036552429\n",
      "59/5 loss:0.05275743454694748\n",
      "60/5 loss:0.06213456019759178\n",
      "61/5 loss:0.15341277420520782\n",
      "62/5 loss:0.0862886905670166\n",
      "63/5 loss:0.07462678849697113\n",
      "64/5 loss:0.11590863019227982\n",
      "65/5 loss:0.09611993283033371\n",
      "66/5 loss:0.1307915300130844\n",
      "67/5 loss:0.0726366862654686\n",
      "68/5 loss:0.13602206110954285\n",
      "69/5 loss:0.0483495369553566\n",
      "70/5 loss:0.045950017869472504\n",
      "71/5 loss:0.08104293793439865\n",
      "72/5 loss:0.16322852671146393\n",
      "73/5 loss:0.10797718167304993\n",
      "74/5 loss:0.09061463177204132\n",
      "75/5 loss:0.13744337856769562\n",
      "76/5 loss:0.1372140347957611\n",
      "77/5 loss:0.06537334620952606\n",
      "78/5 loss:0.11001458764076233\n",
      "79/5 loss:0.15271912515163422\n",
      "80/5 loss:0.09670594334602356\n",
      "81/5 loss:0.22517181932926178\n",
      "82/5 loss:0.2098044604063034\n",
      "83/5 loss:0.060854796320199966\n",
      "84/5 loss:0.05493698641657829\n",
      "85/5 loss:0.1378592699766159\n",
      "86/5 loss:0.08892158418893814\n",
      "87/5 loss:0.08896415680646896\n",
      "88/5 loss:0.11361417919397354\n",
      "89/5 loss:0.05976270139217377\n",
      "90/5 loss:0.06291338056325912\n",
      "91/5 loss:0.06928787380456924\n",
      "92/5 loss:0.06987810879945755\n",
      "93/5 loss:0.1059144139289856\n",
      "94/5 loss:0.08813774585723877\n",
      "95/5 loss:0.09844043105840683\n",
      "96/5 loss:0.07228867709636688\n",
      "97/5 loss:0.18324698507785797\n",
      "98/5 loss:0.10974741727113724\n",
      "99/5 loss:0.07826612889766693\n",
      "100/5 loss:0.07167501002550125\n",
      "101/5 loss:0.10310778766870499\n",
      "102/5 loss:0.11896879971027374\n",
      "103/5 loss:0.18553370237350464\n",
      "104/5 loss:0.19500969350337982\n",
      "105/5 loss:0.09694286435842514\n",
      "106/5 loss:0.0538153350353241\n",
      "107/5 loss:0.08615376800298691\n",
      "108/5 loss:0.09605325013399124\n",
      "109/5 loss:0.06685154139995575\n",
      "110/5 loss:0.08428153395652771\n",
      "111/5 loss:0.18198426067829132\n",
      "112/5 loss:0.20239640772342682\n",
      "113/5 loss:0.20882029831409454\n",
      "114/5 loss:0.06612302362918854\n",
      "115/5 loss:0.08811390399932861\n",
      "116/5 loss:0.09700779616832733\n",
      "117/5 loss:0.2251846343278885\n",
      "118/5 loss:0.11064169555902481\n",
      "119/5 loss:0.2122398167848587\n",
      "Train Epoch: 5\t Loss: 0.212240\n",
      "CPU times: user 38min 25s, sys: 6min 54s, total: 45min 19s\n",
      "Wall time: 6min 1s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 790/836 (94%)\n",
      "\n",
      "1/6 loss:0.08711361885070801\n",
      "2/6 loss:0.12232550978660583\n",
      "3/6 loss:0.20893368124961853\n",
      "4/6 loss:0.04652480036020279\n",
      "5/6 loss:0.10168418288230896\n",
      "6/6 loss:0.10314934700727463\n",
      "7/6 loss:0.13315245509147644\n",
      "8/6 loss:0.1354891061782837\n",
      "9/6 loss:0.11661025136709213\n",
      "10/6 loss:0.09511793404817581\n",
      "11/6 loss:0.08690566569566727\n",
      "12/6 loss:0.07111817598342896\n",
      "13/6 loss:0.08100863546133041\n",
      "14/6 loss:0.022938108071684837\n",
      "15/6 loss:0.19179226458072662\n",
      "16/6 loss:0.055773790925741196\n",
      "17/6 loss:0.08221306651830673\n",
      "18/6 loss:0.1397927850484848\n",
      "19/6 loss:0.07160021364688873\n",
      "20/6 loss:0.04820556566119194\n",
      "21/6 loss:0.07094434648752213\n",
      "22/6 loss:0.12320772558450699\n",
      "23/6 loss:0.0989782065153122\n",
      "24/6 loss:0.10030748695135117\n",
      "25/6 loss:0.07615847885608673\n",
      "26/6 loss:0.07035229355096817\n",
      "27/6 loss:0.14397190511226654\n",
      "28/6 loss:0.05314986780285835\n",
      "29/6 loss:0.041613198816776276\n",
      "30/6 loss:0.08020753413438797\n",
      "31/6 loss:0.0660342127084732\n",
      "32/6 loss:0.3013443052768707\n",
      "33/6 loss:0.10932173579931259\n",
      "34/6 loss:0.10502120107412338\n",
      "35/6 loss:0.10515979677438736\n",
      "36/6 loss:0.14514249563217163\n",
      "37/6 loss:0.16995912790298462\n",
      "38/6 loss:0.1595851629972458\n",
      "39/6 loss:0.15428386628627777\n",
      "40/6 loss:0.0864192470908165\n",
      "41/6 loss:0.071698397397995\n",
      "42/6 loss:0.03878733143210411\n",
      "43/6 loss:0.09640277922153473\n",
      "44/6 loss:0.07988158613443375\n",
      "45/6 loss:0.07130122184753418\n",
      "46/6 loss:0.10129010677337646\n",
      "47/6 loss:0.07938763499259949\n",
      "48/6 loss:0.07681261748075485\n",
      "49/6 loss:0.08082538098096848\n",
      "50/6 loss:0.03215755894780159\n",
      "51/6 loss:0.044601429253816605\n",
      "52/6 loss:0.12559382617473602\n",
      "53/6 loss:0.11715205758810043\n",
      "54/6 loss:0.11648142337799072\n",
      "55/6 loss:0.05298024043440819\n",
      "56/6 loss:0.05830385535955429\n",
      "57/6 loss:0.08969683945178986\n",
      "58/6 loss:0.19475144147872925\n",
      "59/6 loss:0.11855005472898483\n",
      "60/6 loss:0.057009078562259674\n",
      "61/6 loss:0.09492942690849304\n",
      "62/6 loss:0.08196543157100677\n",
      "63/6 loss:0.08955632895231247\n",
      "64/6 loss:0.04012562334537506\n",
      "65/6 loss:0.10328323394060135\n",
      "66/6 loss:0.12337775528430939\n",
      "67/6 loss:0.053919825702905655\n",
      "68/6 loss:0.17706356942653656\n",
      "69/6 loss:0.08340919017791748\n",
      "70/6 loss:0.1311267465353012\n",
      "71/6 loss:0.07003794610500336\n",
      "72/6 loss:0.1840500682592392\n",
      "73/6 loss:0.0602191761136055\n",
      "74/6 loss:0.13923537731170654\n",
      "75/6 loss:0.15879710018634796\n",
      "76/6 loss:0.09262218326330185\n",
      "77/6 loss:0.08298700302839279\n",
      "78/6 loss:0.04968893155455589\n",
      "79/6 loss:0.09007236361503601\n",
      "80/6 loss:0.09661497175693512\n",
      "81/6 loss:0.0853315144777298\n",
      "82/6 loss:0.11092347651720047\n",
      "83/6 loss:0.0847664549946785\n",
      "84/6 loss:0.1593398004770279\n",
      "85/6 loss:0.10297258198261261\n",
      "86/6 loss:0.10525468736886978\n",
      "87/6 loss:0.18784934282302856\n",
      "88/6 loss:0.08997951447963715\n",
      "89/6 loss:0.11305415630340576\n",
      "90/6 loss:0.14429473876953125\n",
      "91/6 loss:0.09831832349300385\n",
      "92/6 loss:0.09886442869901657\n",
      "93/6 loss:0.09795448929071426\n",
      "94/6 loss:0.03794889897108078\n",
      "95/6 loss:0.12922483682632446\n",
      "96/6 loss:0.09791293740272522\n",
      "97/6 loss:0.06386002898216248\n",
      "98/6 loss:0.07125861942768097\n",
      "99/6 loss:0.1500958502292633\n",
      "100/6 loss:0.15438148379325867\n",
      "101/6 loss:0.0402558408677578\n",
      "102/6 loss:0.1307862102985382\n",
      "103/6 loss:0.11949783563613892\n",
      "104/6 loss:0.09484082460403442\n",
      "105/6 loss:0.08357027173042297\n",
      "106/6 loss:0.0952702984213829\n",
      "107/6 loss:0.06540890783071518\n",
      "108/6 loss:0.08000587671995163\n",
      "109/6 loss:0.09630992263555527\n",
      "110/6 loss:0.11160185188055038\n",
      "111/6 loss:0.10851547867059708\n",
      "112/6 loss:0.07043720036745071\n",
      "113/6 loss:0.10419611632823944\n",
      "114/6 loss:0.08458535373210907\n",
      "115/6 loss:0.06474823504686356\n",
      "116/6 loss:0.1465977132320404\n",
      "117/6 loss:0.16753554344177246\n",
      "118/6 loss:0.1107528954744339\n",
      "119/6 loss:0.30817657709121704\n",
      "Train Epoch: 6\t Loss: 0.308177\n",
      "CPU times: user 38min 28s, sys: 6min 58s, total: 45min 26s\n",
      "Wall time: 6min 2s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 810/836 (97%)\n",
      "\n",
      "1/7 loss:0.09210336953401566\n",
      "2/7 loss:0.09602861106395721\n",
      "3/7 loss:0.1143890991806984\n",
      "4/7 loss:0.12964193522930145\n",
      "5/7 loss:0.09525757282972336\n",
      "6/7 loss:0.16444194316864014\n",
      "7/7 loss:0.2352840006351471\n",
      "8/7 loss:0.18792133033275604\n",
      "9/7 loss:0.09469042718410492\n",
      "10/7 loss:0.10190363228321075\n",
      "11/7 loss:0.07775542140007019\n",
      "12/7 loss:0.10329529643058777\n",
      "13/7 loss:0.1210797131061554\n",
      "14/7 loss:0.16115279495716095\n",
      "15/7 loss:0.22169360518455505\n",
      "16/7 loss:0.1364482343196869\n",
      "17/7 loss:0.06687817722558975\n",
      "18/7 loss:0.12008872628211975\n",
      "19/7 loss:0.082736536860466\n",
      "20/7 loss:0.09790588170289993\n",
      "21/7 loss:0.11380375176668167\n",
      "22/7 loss:0.11816485971212387\n",
      "23/7 loss:0.12125370651483536\n",
      "24/7 loss:0.12007668614387512\n",
      "25/7 loss:0.05913989618420601\n",
      "26/7 loss:0.05649808421730995\n",
      "27/7 loss:0.06728008389472961\n",
      "28/7 loss:0.09737320244312286\n",
      "29/7 loss:0.08474501967430115\n",
      "30/7 loss:0.055169422179460526\n",
      "31/7 loss:0.057276930660009384\n",
      "32/7 loss:0.11669667810201645\n",
      "33/7 loss:0.13685858249664307\n",
      "34/7 loss:0.1363522708415985\n",
      "35/7 loss:0.15199881792068481\n",
      "36/7 loss:0.08889632672071457\n",
      "37/7 loss:0.08440893888473511\n",
      "38/7 loss:0.07868138700723648\n",
      "39/7 loss:0.07826068997383118\n",
      "40/7 loss:0.14805547893047333\n",
      "41/7 loss:0.09040255844593048\n",
      "42/7 loss:0.11935853958129883\n",
      "43/7 loss:0.11355891078710556\n",
      "44/7 loss:0.16068759560585022\n",
      "45/7 loss:0.11295188218355179\n",
      "46/7 loss:0.10273870825767517\n",
      "47/7 loss:0.08266445249319077\n",
      "48/7 loss:0.0558522567152977\n",
      "49/7 loss:0.14337928593158722\n",
      "50/7 loss:0.13030385971069336\n",
      "51/7 loss:0.0920550525188446\n",
      "52/7 loss:0.12044314295053482\n",
      "53/7 loss:0.08287441730499268\n",
      "54/7 loss:0.08414663374423981\n",
      "55/7 loss:0.07082726061344147\n",
      "56/7 loss:0.06477471441030502\n",
      "57/7 loss:0.08729377388954163\n",
      "58/7 loss:0.19896765053272247\n",
      "59/7 loss:0.11451210826635361\n",
      "60/7 loss:0.16485820710659027\n",
      "61/7 loss:0.058422062546014786\n",
      "62/7 loss:0.1968463808298111\n",
      "63/7 loss:0.10242294520139694\n",
      "64/7 loss:0.15219438076019287\n",
      "65/7 loss:0.07060162723064423\n",
      "66/7 loss:0.11444707214832306\n",
      "67/7 loss:0.2077150046825409\n",
      "68/7 loss:0.1073603481054306\n",
      "69/7 loss:0.1275482475757599\n",
      "70/7 loss:0.07018966972827911\n",
      "71/7 loss:0.05409796163439751\n",
      "72/7 loss:0.12251204997301102\n",
      "73/7 loss:0.09822016209363937\n",
      "74/7 loss:0.06517148017883301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/7 loss:0.10908971726894379\n",
      "76/7 loss:0.1335083395242691\n",
      "77/7 loss:0.07470786571502686\n",
      "78/7 loss:0.19124835729599\n",
      "79/7 loss:0.06745008379220963\n",
      "80/7 loss:0.1592891961336136\n",
      "81/7 loss:0.08748822659254074\n",
      "82/7 loss:0.08398447930812836\n",
      "83/7 loss:0.09891428798437119\n",
      "84/7 loss:0.13626180589199066\n",
      "85/7 loss:0.13076594471931458\n",
      "86/7 loss:0.07713955640792847\n",
      "87/7 loss:0.13027094304561615\n",
      "88/7 loss:0.04831487312912941\n",
      "89/7 loss:0.13110752403736115\n",
      "90/7 loss:0.07161371409893036\n",
      "91/7 loss:0.0754811018705368\n",
      "92/7 loss:0.08113580197095871\n",
      "93/7 loss:0.14605368673801422\n",
      "94/7 loss:0.08894956111907959\n",
      "95/7 loss:0.10025302320718765\n",
      "96/7 loss:0.05852694436907768\n",
      "97/7 loss:0.1592055708169937\n",
      "98/7 loss:0.07471167296171188\n",
      "99/7 loss:0.052170902490615845\n",
      "100/7 loss:0.10439246147871017\n",
      "101/7 loss:0.12269138544797897\n",
      "102/7 loss:0.03947879374027252\n",
      "103/7 loss:0.14823155105113983\n",
      "104/7 loss:0.06089901551604271\n",
      "105/7 loss:0.06774718314409256\n",
      "106/7 loss:0.09376412630081177\n",
      "107/7 loss:0.06582330912351608\n",
      "108/7 loss:0.08057127892971039\n",
      "109/7 loss:0.08297618478536606\n",
      "110/7 loss:0.06048082187771797\n",
      "111/7 loss:0.07477011531591415\n",
      "112/7 loss:0.08820274472236633\n",
      "113/7 loss:0.08392945677042007\n",
      "114/7 loss:0.07636082917451859\n",
      "115/7 loss:0.0886322483420372\n",
      "116/7 loss:0.04837649688124657\n",
      "117/7 loss:0.1883525848388672\n",
      "118/7 loss:0.08807487785816193\n",
      "119/7 loss:0.3482007384300232\n",
      "Train Epoch: 7\t Loss: 0.348201\n",
      "CPU times: user 38min 32s, sys: 7min, total: 45min 33s\n",
      "Wall time: 6min 4s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 804/836 (96%)\n",
      "\n",
      "1/8 loss:0.06255445629358292\n",
      "2/8 loss:0.1477363407611847\n",
      "3/8 loss:0.06256391108036041\n",
      "4/8 loss:0.10990551859140396\n",
      "5/8 loss:0.23994477093219757\n",
      "6/8 loss:0.22684141993522644\n",
      "7/8 loss:0.14351239800453186\n",
      "8/8 loss:0.13607095181941986\n",
      "9/8 loss:0.11454102396965027\n",
      "10/8 loss:0.17534571886062622\n",
      "11/8 loss:0.0440470427274704\n",
      "12/8 loss:0.10068584233522415\n",
      "13/8 loss:0.09615680575370789\n",
      "14/8 loss:0.24175560474395752\n",
      "15/8 loss:0.14281287789344788\n",
      "16/8 loss:0.1606028974056244\n",
      "17/8 loss:0.05827529355883598\n",
      "18/8 loss:0.13847611844539642\n",
      "19/8 loss:0.11394864320755005\n",
      "20/8 loss:0.15598689019680023\n",
      "21/8 loss:0.07366862148046494\n",
      "22/8 loss:0.10157574713230133\n",
      "23/8 loss:0.15852907299995422\n",
      "24/8 loss:0.09241639077663422\n",
      "25/8 loss:0.2994537651538849\n",
      "26/8 loss:0.0908302515745163\n",
      "27/8 loss:0.1832958459854126\n",
      "28/8 loss:0.10006234794855118\n",
      "29/8 loss:0.1303124576807022\n",
      "30/8 loss:0.06823186576366425\n",
      "31/8 loss:0.0707051157951355\n",
      "32/8 loss:0.1439245343208313\n",
      "33/8 loss:0.08520931005477905\n",
      "34/8 loss:0.08289698511362076\n",
      "35/8 loss:0.06462320685386658\n",
      "36/8 loss:0.12354782223701477\n",
      "37/8 loss:0.07473618537187576\n",
      "38/8 loss:0.24039432406425476\n",
      "39/8 loss:0.05675844848155975\n",
      "40/8 loss:0.1273978054523468\n",
      "41/8 loss:0.08358965069055557\n",
      "42/8 loss:0.09145675599575043\n",
      "43/8 loss:0.16207413375377655\n",
      "44/8 loss:0.06345383822917938\n",
      "45/8 loss:0.06584160029888153\n",
      "46/8 loss:0.14310523867607117\n",
      "47/8 loss:0.1718168556690216\n",
      "48/8 loss:0.07421140372753143\n",
      "49/8 loss:0.052161138504743576\n",
      "50/8 loss:0.04297623783349991\n",
      "51/8 loss:0.13046126067638397\n",
      "52/8 loss:0.1763605773448944\n",
      "53/8 loss:0.06930378079414368\n",
      "54/8 loss:0.10718410462141037\n",
      "55/8 loss:0.07568886876106262\n",
      "56/8 loss:0.06111128255724907\n",
      "57/8 loss:0.056867726147174835\n",
      "58/8 loss:0.08604002743959427\n",
      "59/8 loss:0.060911115258932114\n",
      "60/8 loss:0.09874104708433151\n",
      "61/8 loss:0.0715530663728714\n",
      "62/8 loss:0.20880642533302307\n",
      "63/8 loss:0.0683164894580841\n",
      "64/8 loss:0.11594550311565399\n",
      "65/8 loss:0.13139116764068604\n",
      "66/8 loss:0.12844008207321167\n",
      "67/8 loss:0.06752963364124298\n",
      "68/8 loss:0.09636885672807693\n",
      "69/8 loss:0.17411230504512787\n",
      "70/8 loss:0.1643364280462265\n",
      "71/8 loss:0.22535201907157898\n",
      "72/8 loss:0.05717679485678673\n",
      "73/8 loss:0.09232298284769058\n",
      "74/8 loss:0.04265480861067772\n",
      "75/8 loss:0.04451233521103859\n",
      "76/8 loss:0.1893509179353714\n",
      "77/8 loss:0.20662707090377808\n",
      "78/8 loss:0.16137129068374634\n",
      "79/8 loss:0.08688203990459442\n",
      "80/8 loss:0.13642702996730804\n",
      "81/8 loss:0.06761443614959717\n",
      "82/8 loss:0.10045911371707916\n",
      "83/8 loss:0.12137042731046677\n",
      "84/8 loss:0.06547775864601135\n",
      "85/8 loss:0.19344787299633026\n",
      "86/8 loss:0.0727386549115181\n",
      "87/8 loss:0.10773389786481857\n",
      "88/8 loss:0.051926810294389725\n",
      "89/8 loss:0.08829034119844437\n",
      "90/8 loss:0.06061830371618271\n",
      "91/8 loss:0.043202899396419525\n",
      "92/8 loss:0.0778547003865242\n",
      "93/8 loss:0.07008633762598038\n",
      "94/8 loss:0.20756228268146515\n",
      "95/8 loss:0.061280883848667145\n",
      "96/8 loss:0.0948668122291565\n",
      "97/8 loss:0.15195733308792114\n",
      "98/8 loss:0.16227418184280396\n",
      "99/8 loss:0.0938362330198288\n",
      "100/8 loss:0.11292119324207306\n",
      "101/8 loss:0.1109691709280014\n",
      "102/8 loss:0.06000276654958725\n",
      "103/8 loss:0.09207626432180405\n",
      "104/8 loss:0.08405157923698425\n",
      "105/8 loss:0.20671561360359192\n",
      "106/8 loss:0.08278956264257431\n",
      "107/8 loss:0.09147153049707413\n",
      "108/8 loss:0.14087170362472534\n",
      "109/8 loss:0.08150756359100342\n",
      "110/8 loss:0.21453723311424255\n",
      "111/8 loss:0.04086508974432945\n",
      "112/8 loss:0.1397567093372345\n",
      "113/8 loss:0.11061568558216095\n",
      "114/8 loss:0.08585938066244125\n",
      "115/8 loss:0.05804235115647316\n",
      "116/8 loss:0.07671910524368286\n",
      "117/8 loss:0.12708020210266113\n",
      "118/8 loss:0.10477139055728912\n",
      "119/8 loss:0.03316492214798927\n",
      "Train Epoch: 8\t Loss: 0.033165\n",
      "CPU times: user 38min 34s, sys: 6min 58s, total: 45min 33s\n",
      "Wall time: 6min 4s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 807/836 (97%)\n",
      "\n",
      "1/9 loss:0.07127977907657623\n",
      "2/9 loss:0.08323872089385986\n",
      "3/9 loss:0.09757469594478607\n",
      "4/9 loss:0.12232372164726257\n",
      "5/9 loss:0.09979738295078278\n",
      "6/9 loss:0.08361464738845825\n",
      "7/9 loss:0.08427694439888\n",
      "8/9 loss:0.07313235849142075\n",
      "9/9 loss:0.08477899432182312\n",
      "10/9 loss:0.03769305720925331\n",
      "11/9 loss:0.10840826481580734\n",
      "12/9 loss:0.10471000522375107\n",
      "13/9 loss:0.05908158794045448\n",
      "14/9 loss:0.11423945426940918\n",
      "15/9 loss:0.07040705531835556\n",
      "16/9 loss:0.1032823845744133\n",
      "17/9 loss:0.11421465128660202\n",
      "18/9 loss:0.11209788173437119\n",
      "19/9 loss:0.03966906666755676\n",
      "20/9 loss:0.04948090761899948\n",
      "21/9 loss:0.0703396275639534\n",
      "22/9 loss:0.11831934750080109\n",
      "23/9 loss:0.11279642581939697\n",
      "24/9 loss:0.1035093292593956\n",
      "25/9 loss:0.06935831904411316\n",
      "26/9 loss:0.08075377345085144\n",
      "27/9 loss:0.1764502078294754\n",
      "28/9 loss:0.06514641642570496\n",
      "29/9 loss:0.04712477698922157\n",
      "30/9 loss:0.06398671120405197\n",
      "31/9 loss:0.06447692215442657\n",
      "32/9 loss:0.0534004382789135\n",
      "33/9 loss:0.14806653559207916\n",
      "34/9 loss:0.08978693187236786\n",
      "35/9 loss:0.14000411331653595\n",
      "36/9 loss:0.10463134199380875\n",
      "37/9 loss:0.09540732949972153\n",
      "38/9 loss:0.09934251010417938\n",
      "39/9 loss:0.1000552847981453\n",
      "40/9 loss:0.06129559874534607\n",
      "41/9 loss:0.02305646985769272\n",
      "42/9 loss:0.05859793722629547\n",
      "43/9 loss:0.05801228806376457\n",
      "44/9 loss:0.13634903728961945\n",
      "45/9 loss:0.0601838044822216\n",
      "46/9 loss:0.07317144423723221\n",
      "47/9 loss:0.09889935702085495\n",
      "48/9 loss:0.09356115758419037\n",
      "49/9 loss:0.12302350252866745\n",
      "50/9 loss:0.06765162944793701\n",
      "51/9 loss:0.1187550276517868\n",
      "52/9 loss:0.0853370651602745\n",
      "53/9 loss:0.10052963346242905\n",
      "54/9 loss:0.10948116332292557\n",
      "55/9 loss:0.12617826461791992\n",
      "56/9 loss:0.12377188354730606\n",
      "57/9 loss:0.04900446906685829\n",
      "58/9 loss:0.15988881886005402\n",
      "59/9 loss:0.15601405501365662\n",
      "60/9 loss:0.15721730887889862\n",
      "61/9 loss:0.06922964751720428\n",
      "62/9 loss:0.07222501188516617\n",
      "63/9 loss:0.05541675165295601\n",
      "64/9 loss:0.1065903976559639\n",
      "65/9 loss:0.1641668826341629\n",
      "66/9 loss:0.08807211369276047\n",
      "67/9 loss:0.10775551199913025\n",
      "68/9 loss:0.089202381670475\n",
      "69/9 loss:0.10229898244142532\n",
      "70/9 loss:0.09074448049068451\n",
      "71/9 loss:0.13747082650661469\n",
      "72/9 loss:0.13286179304122925\n",
      "73/9 loss:0.183176189661026\n",
      "74/9 loss:0.06074771285057068\n",
      "75/9 loss:0.09035766869783401\n",
      "76/9 loss:0.0924505740404129\n",
      "77/9 loss:0.06065572053194046\n",
      "78/9 loss:0.09666838496923447\n",
      "79/9 loss:0.05655936151742935\n",
      "80/9 loss:0.08917208760976791\n",
      "81/9 loss:0.0801849216222763\n",
      "82/9 loss:0.27809205651283264\n",
      "83/9 loss:0.1461847424507141\n",
      "84/9 loss:0.06530272215604782\n",
      "85/9 loss:0.07043754309415817\n",
      "86/9 loss:0.08837787806987762\n",
      "87/9 loss:0.12569761276245117\n",
      "88/9 loss:0.1330493539571762\n",
      "89/9 loss:0.18476685881614685\n",
      "90/9 loss:0.14969129860401154\n",
      "91/9 loss:0.09665680676698685\n",
      "92/9 loss:0.09206736087799072\n",
      "93/9 loss:0.15957002341747284\n",
      "94/9 loss:0.037195563316345215\n",
      "95/9 loss:0.15339696407318115\n",
      "96/9 loss:0.0782305896282196\n",
      "97/9 loss:0.10887135565280914\n",
      "98/9 loss:0.08377651125192642\n",
      "99/9 loss:0.11138531565666199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/9 loss:0.1485787034034729\n",
      "101/9 loss:0.041059959679841995\n",
      "102/9 loss:0.13670992851257324\n",
      "103/9 loss:0.12642362713813782\n",
      "104/9 loss:0.07285613566637039\n",
      "105/9 loss:0.0932246744632721\n",
      "106/9 loss:0.1422606110572815\n",
      "107/9 loss:0.18335309624671936\n",
      "108/9 loss:0.08035010099411011\n",
      "109/9 loss:0.04744720458984375\n",
      "110/9 loss:0.10318626463413239\n",
      "111/9 loss:0.08819602429866791\n",
      "112/9 loss:0.14790098369121552\n",
      "113/9 loss:0.11886490136384964\n",
      "114/9 loss:0.0838012546300888\n",
      "115/9 loss:0.10437491536140442\n",
      "116/9 loss:0.08519183844327927\n",
      "117/9 loss:0.15035919845104218\n",
      "118/9 loss:0.11312036961317062\n",
      "119/9 loss:0.3021504282951355\n",
      "Train Epoch: 9\t Loss: 0.302150\n",
      "CPU times: user 38min 34s, sys: 6min 57s, total: 45min 32s\n",
      "Wall time: 6min 3s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 809/836 (97%)\n",
      "\n",
      "1/10 loss:0.040301449596881866\n",
      "2/10 loss:0.08125396072864532\n",
      "3/10 loss:0.04196557402610779\n",
      "4/10 loss:0.23223088681697845\n",
      "5/10 loss:0.07328856736421585\n",
      "6/10 loss:0.06990347802639008\n",
      "7/10 loss:0.14597100019454956\n",
      "8/10 loss:0.19013646245002747\n",
      "9/10 loss:0.041900135576725006\n",
      "10/10 loss:0.10793399810791016\n",
      "11/10 loss:0.07344263792037964\n",
      "12/10 loss:0.07490482181310654\n",
      "13/10 loss:0.09885850548744202\n",
      "14/10 loss:0.09811975061893463\n",
      "15/10 loss:0.06397920101881027\n",
      "16/10 loss:0.060722559690475464\n",
      "17/10 loss:0.15707555413246155\n",
      "18/10 loss:0.14386379718780518\n",
      "19/10 loss:0.06517107039690018\n",
      "20/10 loss:0.11541130393743515\n",
      "21/10 loss:0.21330417692661285\n",
      "22/10 loss:0.17090196907520294\n",
      "23/10 loss:0.06668511778116226\n",
      "24/10 loss:0.18070897459983826\n",
      "25/10 loss:0.10041772574186325\n",
      "26/10 loss:0.1545802801847458\n",
      "27/10 loss:0.09504422545433044\n",
      "28/10 loss:0.09357524663209915\n",
      "29/10 loss:0.08817216008901596\n",
      "30/10 loss:0.07692926377058029\n",
      "31/10 loss:0.0871439278125763\n",
      "32/10 loss:0.11017507314682007\n",
      "33/10 loss:0.05340312048792839\n",
      "34/10 loss:0.13467954099178314\n",
      "35/10 loss:0.11341826617717743\n",
      "36/10 loss:0.13926315307617188\n",
      "37/10 loss:0.04566990211606026\n",
      "38/10 loss:0.04341454431414604\n",
      "39/10 loss:0.12404954433441162\n",
      "40/10 loss:0.04895010590553284\n",
      "41/10 loss:0.10398245602846146\n",
      "42/10 loss:0.19785813987255096\n",
      "43/10 loss:0.1576797068119049\n",
      "44/10 loss:0.11439808458089828\n",
      "45/10 loss:0.06260132044553757\n",
      "46/10 loss:0.10253619402647018\n",
      "47/10 loss:0.1388043910264969\n",
      "48/10 loss:0.08329164981842041\n",
      "49/10 loss:0.05050256848335266\n",
      "50/10 loss:0.1337060034275055\n",
      "51/10 loss:0.15891702473163605\n",
      "52/10 loss:0.036776669323444366\n",
      "53/10 loss:0.1582363396883011\n",
      "54/10 loss:0.1306481659412384\n",
      "55/10 loss:0.1420411318540573\n",
      "56/10 loss:0.08718648552894592\n",
      "57/10 loss:0.11457682400941849\n",
      "58/10 loss:0.060603316873311996\n",
      "59/10 loss:0.05742669105529785\n",
      "60/10 loss:0.09593541920185089\n",
      "61/10 loss:0.0666271299123764\n",
      "62/10 loss:0.11350774765014648\n",
      "63/10 loss:0.11011368781328201\n",
      "64/10 loss:0.183962881565094\n",
      "65/10 loss:0.14786334335803986\n",
      "66/10 loss:0.06955697387456894\n",
      "67/10 loss:0.070552758872509\n",
      "68/10 loss:0.21884198486804962\n",
      "69/10 loss:0.10731375962495804\n",
      "70/10 loss:0.06889966130256653\n",
      "71/10 loss:0.13221830129623413\n",
      "72/10 loss:0.08361400663852692\n",
      "73/10 loss:0.09399767965078354\n",
      "74/10 loss:0.08052883297204971\n",
      "75/10 loss:0.08177414536476135\n",
      "76/10 loss:0.09094514697790146\n",
      "77/10 loss:0.09895233064889908\n",
      "78/10 loss:0.05868057161569595\n",
      "79/10 loss:0.03080805577337742\n",
      "80/10 loss:0.06461530178785324\n",
      "81/10 loss:0.060310669243335724\n",
      "82/10 loss:0.09670432657003403\n",
      "83/10 loss:0.09327161312103271\n",
      "84/10 loss:0.10326529294252396\n",
      "85/10 loss:0.06168198585510254\n",
      "86/10 loss:0.13823974132537842\n",
      "87/10 loss:0.08945871889591217\n",
      "88/10 loss:0.11521818488836288\n",
      "89/10 loss:0.15628758072853088\n",
      "90/10 loss:0.10120642185211182\n",
      "91/10 loss:0.06291667371988297\n",
      "92/10 loss:0.09560057520866394\n",
      "93/10 loss:0.18339112401008606\n",
      "94/10 loss:0.0742124617099762\n",
      "95/10 loss:0.03259305655956268\n",
      "96/10 loss:0.06663940101861954\n",
      "97/10 loss:0.08640950173139572\n",
      "98/10 loss:0.11260364949703217\n",
      "99/10 loss:0.12310454994440079\n",
      "100/10 loss:0.1376039683818817\n",
      "101/10 loss:0.08625195920467377\n",
      "102/10 loss:0.05274689197540283\n",
      "103/10 loss:0.08480500429868698\n",
      "104/10 loss:0.07694102078676224\n",
      "105/10 loss:0.07722851634025574\n",
      "106/10 loss:0.10367178916931152\n",
      "107/10 loss:0.1694139987230301\n",
      "108/10 loss:0.02212490700185299\n",
      "109/10 loss:0.05888644605875015\n",
      "110/10 loss:0.12493191659450531\n",
      "111/10 loss:0.1961582452058792\n",
      "112/10 loss:0.04437130689620972\n",
      "113/10 loss:0.19439613819122314\n",
      "114/10 loss:0.15854844450950623\n",
      "115/10 loss:0.10497438907623291\n",
      "116/10 loss:0.04535729065537453\n",
      "117/10 loss:0.05945784971117973\n",
      "118/10 loss:0.07238297164440155\n",
      "119/10 loss:0.07236870378255844\n",
      "Train Epoch: 10\t Loss: 0.072369\n",
      "CPU times: user 38min 31s, sys: 6min 57s, total: 45min 28s\n",
      "Wall time: 6min 2s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 804/836 (96%)\n",
      "\n",
      "1/11 loss:0.05440238490700722\n",
      "2/11 loss:0.1595151424407959\n",
      "3/11 loss:0.11489327251911163\n",
      "4/11 loss:0.05215923860669136\n",
      "5/11 loss:0.06531349569559097\n",
      "6/11 loss:0.06930573284626007\n",
      "7/11 loss:0.04045886546373367\n",
      "8/11 loss:0.09439022094011307\n",
      "9/11 loss:0.09861723333597183\n",
      "10/11 loss:0.18647858500480652\n",
      "11/11 loss:0.17376038432121277\n",
      "12/11 loss:0.10527590662240982\n",
      "13/11 loss:0.08144072443246841\n",
      "14/11 loss:0.12733586132526398\n",
      "15/11 loss:0.1311446577310562\n",
      "16/11 loss:0.04343847185373306\n",
      "17/11 loss:0.1622319370508194\n",
      "18/11 loss:0.03993235528469086\n",
      "19/11 loss:0.07997159659862518\n",
      "20/11 loss:0.07612902671098709\n",
      "21/11 loss:0.05121945962309837\n",
      "22/11 loss:0.08420248329639435\n",
      "23/11 loss:0.11137811094522476\n",
      "24/11 loss:0.12169964611530304\n",
      "25/11 loss:0.1073947623372078\n",
      "26/11 loss:0.06329973042011261\n",
      "27/11 loss:0.10807324200868607\n",
      "28/11 loss:0.08340302109718323\n",
      "29/11 loss:0.07665641605854034\n",
      "30/11 loss:0.08096744865179062\n",
      "31/11 loss:0.14314651489257812\n",
      "32/11 loss:0.11438791453838348\n",
      "33/11 loss:0.08143294602632523\n",
      "34/11 loss:0.09826553612947464\n",
      "35/11 loss:0.052897218614816666\n",
      "36/11 loss:0.052661627531051636\n",
      "37/11 loss:0.05041593685746193\n",
      "38/11 loss:0.12008219957351685\n",
      "39/11 loss:0.0700138583779335\n",
      "40/11 loss:0.14489462971687317\n",
      "41/11 loss:0.1015959233045578\n",
      "42/11 loss:0.09402729570865631\n",
      "43/11 loss:0.09072455018758774\n",
      "44/11 loss:0.053738415241241455\n",
      "45/11 loss:0.21966606378555298\n",
      "46/11 loss:0.05028640851378441\n",
      "47/11 loss:0.05388881638646126\n",
      "48/11 loss:0.075883649289608\n",
      "49/11 loss:0.11311247199773788\n",
      "50/11 loss:0.10056351870298386\n",
      "51/11 loss:0.12256229668855667\n",
      "52/11 loss:0.15599840879440308\n",
      "53/11 loss:0.09048987925052643\n",
      "54/11 loss:0.10789097845554352\n",
      "55/11 loss:0.12268366664648056\n",
      "56/11 loss:0.13481593132019043\n",
      "57/11 loss:0.04815711826086044\n",
      "58/11 loss:0.07229102402925491\n",
      "59/11 loss:0.12090624868869781\n",
      "60/11 loss:0.07522794604301453\n",
      "61/11 loss:0.08725801110267639\n",
      "62/11 loss:0.089308962225914\n",
      "63/11 loss:0.06587228924036026\n",
      "64/11 loss:0.101921945810318\n",
      "65/11 loss:0.21960386633872986\n",
      "66/11 loss:0.04683348909020424\n",
      "67/11 loss:0.08921502530574799\n",
      "68/11 loss:0.08446048945188522\n",
      "69/11 loss:0.10552399605512619\n",
      "70/11 loss:0.044766247272491455\n",
      "71/11 loss:0.08132552355527878\n",
      "72/11 loss:0.11174727976322174\n",
      "73/11 loss:0.1206691637635231\n",
      "74/11 loss:0.057567186653614044\n",
      "75/11 loss:0.16280847787857056\n",
      "76/11 loss:0.04344170540571213\n",
      "77/11 loss:0.08531718701124191\n",
      "78/11 loss:0.05175665393471718\n",
      "79/11 loss:0.07128982245922089\n",
      "80/11 loss:0.11794321238994598\n",
      "81/11 loss:0.07599016278982162\n",
      "82/11 loss:0.03044157661497593\n",
      "83/11 loss:0.11085651069879532\n",
      "84/11 loss:0.049997661262750626\n",
      "85/11 loss:0.2073623239994049\n",
      "86/11 loss:0.07070400565862656\n",
      "87/11 loss:0.08612939715385437\n",
      "88/11 loss:0.14694859087467194\n",
      "89/11 loss:0.06640925258398056\n",
      "90/11 loss:0.20023873448371887\n",
      "91/11 loss:0.05769429728388786\n",
      "92/11 loss:0.1019418016076088\n",
      "93/11 loss:0.13682921230793\n",
      "94/11 loss:0.15220396220684052\n",
      "95/11 loss:0.0741942971944809\n",
      "96/11 loss:0.07032578438520432\n",
      "97/11 loss:0.17067576944828033\n",
      "98/11 loss:0.08378928154706955\n",
      "99/11 loss:0.04159296303987503\n",
      "100/11 loss:0.0749005600810051\n",
      "101/11 loss:0.07758737355470657\n",
      "102/11 loss:0.050180815160274506\n",
      "103/11 loss:0.09904126077890396\n",
      "104/11 loss:0.06010173633694649\n",
      "105/11 loss:0.08207763731479645\n",
      "106/11 loss:0.0718328207731247\n",
      "107/11 loss:0.11548379063606262\n",
      "108/11 loss:0.09092988818883896\n",
      "109/11 loss:0.040727194398641586\n",
      "110/11 loss:0.052804164588451385\n",
      "111/11 loss:0.20441944897174835\n",
      "112/11 loss:0.09472103416919708\n",
      "113/11 loss:0.11570103466510773\n",
      "114/11 loss:0.27753371000289917\n",
      "115/11 loss:0.10482020676136017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/11 loss:0.07409248501062393\n",
      "117/11 loss:0.09254149347543716\n",
      "118/11 loss:0.19013866782188416\n",
      "119/11 loss:0.3386475741863251\n",
      "Train Epoch: 11\t Loss: 0.338648\n",
      "CPU times: user 38min 26s, sys: 6min 57s, total: 45min 24s\n",
      "Wall time: 6min 1s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 794/836 (95%)\n",
      "\n",
      "1/12 loss:0.08701982349157333\n",
      "2/12 loss:0.1017785295844078\n",
      "3/12 loss:0.06798118352890015\n",
      "4/12 loss:0.2279626578092575\n",
      "5/12 loss:0.1565045863389969\n",
      "6/12 loss:0.045022569596767426\n",
      "7/12 loss:0.15230435132980347\n",
      "8/12 loss:0.1275540590286255\n",
      "9/12 loss:0.06678394973278046\n",
      "10/12 loss:0.04702453315258026\n",
      "11/12 loss:0.0574677512049675\n",
      "12/12 loss:0.06015707179903984\n",
      "13/12 loss:0.08541208505630493\n",
      "14/12 loss:0.12731891870498657\n",
      "15/12 loss:0.15957511961460114\n",
      "16/12 loss:0.06438883394002914\n",
      "17/12 loss:0.0657636895775795\n",
      "18/12 loss:0.16160129010677338\n",
      "19/12 loss:0.10581287741661072\n",
      "20/12 loss:0.09996799379587173\n",
      "21/12 loss:0.07892382889986038\n",
      "22/12 loss:0.1561901718378067\n",
      "23/12 loss:0.0416080616414547\n",
      "24/12 loss:0.03630010411143303\n",
      "25/12 loss:0.07144280523061752\n",
      "26/12 loss:0.08959031105041504\n",
      "27/12 loss:0.05219482257962227\n",
      "28/12 loss:0.15659752488136292\n",
      "29/12 loss:0.07299961149692535\n",
      "30/12 loss:0.21714861690998077\n",
      "31/12 loss:0.13004380464553833\n",
      "32/12 loss:0.07229479402303696\n",
      "33/12 loss:0.08943182975053787\n",
      "34/12 loss:0.11996828764677048\n",
      "35/12 loss:0.12126827985048294\n",
      "36/12 loss:0.19128918647766113\n",
      "37/12 loss:0.057266104966402054\n",
      "38/12 loss:0.16466641426086426\n",
      "39/12 loss:0.0860319659113884\n",
      "40/12 loss:0.09613584727048874\n",
      "41/12 loss:0.06234290823340416\n",
      "42/12 loss:0.053606804460287094\n",
      "43/12 loss:0.14534619450569153\n",
      "44/12 loss:0.0629105418920517\n",
      "45/12 loss:0.048548877239227295\n",
      "46/12 loss:0.1863429993391037\n",
      "47/12 loss:0.09367746859788895\n",
      "48/12 loss:0.11216508597135544\n",
      "49/12 loss:0.10950183868408203\n",
      "50/12 loss:0.06134054437279701\n",
      "51/12 loss:0.0566280335187912\n",
      "52/12 loss:0.07033088058233261\n",
      "53/12 loss:0.10204405337572098\n",
      "54/12 loss:0.06690531224012375\n",
      "55/12 loss:0.08978069573640823\n",
      "56/12 loss:0.08201209455728531\n",
      "57/12 loss:0.1269305944442749\n",
      "58/12 loss:0.11172131448984146\n",
      "59/12 loss:0.09891148656606674\n",
      "60/12 loss:0.10318146646022797\n",
      "61/12 loss:0.04633424058556557\n",
      "62/12 loss:0.12645049393177032\n",
      "63/12 loss:0.08430831134319305\n",
      "64/12 loss:0.04002921283245087\n",
      "65/12 loss:0.1658729761838913\n",
      "66/12 loss:0.11507746577262878\n",
      "67/12 loss:0.18259620666503906\n",
      "68/12 loss:0.07060737907886505\n",
      "69/12 loss:0.04053756222128868\n",
      "70/12 loss:0.05710463598370552\n",
      "71/12 loss:0.16617360711097717\n",
      "72/12 loss:0.12095139920711517\n",
      "73/12 loss:0.048801496624946594\n",
      "74/12 loss:0.07911018282175064\n",
      "75/12 loss:0.05780721828341484\n",
      "76/12 loss:0.11710222065448761\n",
      "77/12 loss:0.08648863434791565\n",
      "78/12 loss:0.10451129823923111\n",
      "79/12 loss:0.1254039704799652\n",
      "80/12 loss:0.09022017568349838\n",
      "81/12 loss:0.05362609028816223\n",
      "82/12 loss:0.043776798993349075\n",
      "83/12 loss:0.062371306121349335\n",
      "84/12 loss:0.13144798576831818\n",
      "85/12 loss:0.16813328862190247\n",
      "86/12 loss:0.06620773673057556\n",
      "87/12 loss:0.16309045255184174\n",
      "88/12 loss:0.09225437790155411\n",
      "89/12 loss:0.12443305552005768\n",
      "90/12 loss:0.10892870277166367\n",
      "91/12 loss:0.09513778239488602\n",
      "92/12 loss:0.14392967522144318\n",
      "93/12 loss:0.0854860171675682\n",
      "94/12 loss:0.14327937364578247\n",
      "95/12 loss:0.0659576877951622\n",
      "96/12 loss:0.05593886971473694\n",
      "97/12 loss:0.060604460537433624\n",
      "98/12 loss:0.13038356602191925\n",
      "99/12 loss:0.07027099281549454\n",
      "100/12 loss:0.041106123477220535\n",
      "101/12 loss:0.10433407127857208\n",
      "102/12 loss:0.11398961395025253\n",
      "103/12 loss:0.16166281700134277\n",
      "104/12 loss:0.08278772234916687\n",
      "105/12 loss:0.17887656390666962\n",
      "106/12 loss:0.05935869365930557\n",
      "107/12 loss:0.1376025229692459\n",
      "108/12 loss:0.12716266512870789\n",
      "109/12 loss:0.14028914272785187\n",
      "110/12 loss:0.07373235374689102\n",
      "111/12 loss:0.11436881870031357\n",
      "112/12 loss:0.14401470124721527\n",
      "113/12 loss:0.13474076986312866\n",
      "114/12 loss:0.11894237250089645\n",
      "115/12 loss:0.15161658823490143\n",
      "116/12 loss:0.09707514941692352\n",
      "117/12 loss:0.08734654635190964\n",
      "118/12 loss:0.06053443253040314\n",
      "119/12 loss:0.1106535866856575\n",
      "Train Epoch: 12\t Loss: 0.110654\n",
      "CPU times: user 38min 22s, sys: 6min 52s, total: 45min 15s\n",
      "Wall time: 6min\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 810/836 (97%)\n",
      "\n",
      "1/13 loss:0.06236115097999573\n",
      "2/13 loss:0.13507404923439026\n",
      "3/13 loss:0.06656810641288757\n",
      "4/13 loss:0.1347859501838684\n",
      "5/13 loss:0.14409425854682922\n",
      "6/13 loss:0.06539256870746613\n",
      "7/13 loss:0.09266483783721924\n",
      "8/13 loss:0.10455047339200974\n",
      "9/13 loss:0.08990868180990219\n",
      "10/13 loss:0.18337476253509521\n",
      "11/13 loss:0.06299372017383575\n",
      "12/13 loss:0.13901564478874207\n",
      "13/13 loss:0.14595329761505127\n",
      "14/13 loss:0.10813461244106293\n",
      "15/13 loss:0.044871602207422256\n",
      "16/13 loss:0.09869948774576187\n",
      "17/13 loss:0.05722001940011978\n",
      "18/13 loss:0.11188306659460068\n",
      "19/13 loss:0.07778757810592651\n",
      "20/13 loss:0.03438851237297058\n",
      "21/13 loss:0.07538165897130966\n",
      "22/13 loss:0.13374926149845123\n",
      "23/13 loss:0.15672387182712555\n",
      "24/13 loss:0.10804018378257751\n",
      "25/13 loss:0.13397018611431122\n",
      "26/13 loss:0.09828804433345795\n",
      "27/13 loss:0.0550471730530262\n",
      "28/13 loss:0.15234193205833435\n",
      "29/13 loss:0.11326093971729279\n",
      "30/13 loss:0.10323400795459747\n",
      "31/13 loss:0.14232681691646576\n",
      "32/13 loss:0.08925401419401169\n",
      "33/13 loss:0.08096867799758911\n",
      "34/13 loss:0.0802929550409317\n",
      "35/13 loss:0.10139656066894531\n",
      "36/13 loss:0.08263090997934341\n",
      "37/13 loss:0.06358563899993896\n",
      "38/13 loss:0.06132431700825691\n",
      "39/13 loss:0.09363467246294022\n",
      "40/13 loss:0.15563347935676575\n",
      "41/13 loss:0.10418283194303513\n",
      "42/13 loss:0.0965399220585823\n",
      "43/13 loss:0.048256054520606995\n",
      "44/13 loss:0.18320901691913605\n",
      "45/13 loss:0.06557915359735489\n",
      "46/13 loss:0.16711048781871796\n",
      "47/13 loss:0.05264979228377342\n",
      "48/13 loss:0.063404381275177\n",
      "49/13 loss:0.11589697748422623\n",
      "50/13 loss:0.057179294526576996\n",
      "51/13 loss:0.11653667688369751\n",
      "52/13 loss:0.08394304662942886\n",
      "53/13 loss:0.06604652106761932\n",
      "54/13 loss:0.04106685519218445\n",
      "55/13 loss:0.0842064619064331\n",
      "56/13 loss:0.07062048465013504\n",
      "57/13 loss:0.10803431272506714\n",
      "58/13 loss:0.15040256083011627\n",
      "59/13 loss:0.07588303089141846\n",
      "60/13 loss:0.058370500802993774\n",
      "61/13 loss:0.07703503221273422\n",
      "62/13 loss:0.0806141123175621\n",
      "63/13 loss:0.06914890557527542\n",
      "64/13 loss:0.07688087970018387\n",
      "65/13 loss:0.04095647111535072\n",
      "66/13 loss:0.07517461478710175\n",
      "67/13 loss:0.08655967563390732\n",
      "68/13 loss:0.05669044703245163\n",
      "69/13 loss:0.06630951911211014\n",
      "70/13 loss:0.04561826214194298\n",
      "71/13 loss:0.06030643731355667\n",
      "72/13 loss:0.06161453574895859\n",
      "73/13 loss:0.07577912509441376\n",
      "74/13 loss:0.1358409821987152\n",
      "75/13 loss:0.10196667164564133\n",
      "76/13 loss:0.17146337032318115\n",
      "77/13 loss:0.10540274530649185\n",
      "78/13 loss:0.1371270716190338\n",
      "79/13 loss:0.0785118043422699\n",
      "80/13 loss:0.11259306222200394\n",
      "81/13 loss:0.09294018894433975\n",
      "82/13 loss:0.15126094222068787\n",
      "83/13 loss:0.05462134629487991\n",
      "84/13 loss:0.0654848963022232\n",
      "85/13 loss:0.1190657839179039\n",
      "86/13 loss:0.05209791660308838\n",
      "87/13 loss:0.06084037944674492\n",
      "88/13 loss:0.06153375655412674\n",
      "89/13 loss:0.08757957071065903\n",
      "90/13 loss:0.23573625087738037\n",
      "91/13 loss:0.18098339438438416\n",
      "92/13 loss:0.10301611572504044\n",
      "93/13 loss:0.11449028551578522\n",
      "94/13 loss:0.07721355557441711\n",
      "95/13 loss:0.20785008370876312\n",
      "96/13 loss:0.07647276669740677\n",
      "97/13 loss:0.0933794304728508\n",
      "98/13 loss:0.0875580906867981\n",
      "99/13 loss:0.07869776338338852\n",
      "100/13 loss:0.08187460154294968\n",
      "101/13 loss:0.08946891129016876\n",
      "102/13 loss:0.09572090208530426\n",
      "103/13 loss:0.03476006165146828\n",
      "104/13 loss:0.10177496075630188\n",
      "105/13 loss:0.21174563467502594\n",
      "106/13 loss:0.18285652995109558\n",
      "107/13 loss:0.09470026195049286\n",
      "108/13 loss:0.07261057198047638\n",
      "109/13 loss:0.10073774307966232\n",
      "110/13 loss:0.10102783888578415\n",
      "111/13 loss:0.1457856297492981\n",
      "112/13 loss:0.20117157697677612\n",
      "113/13 loss:0.05959893763065338\n",
      "114/13 loss:0.08102703094482422\n",
      "115/13 loss:0.10231924057006836\n",
      "116/13 loss:0.09170505404472351\n",
      "117/13 loss:0.0855344608426094\n",
      "118/13 loss:0.16483056545257568\n",
      "119/13 loss:1.6903983354568481\n",
      "Train Epoch: 13\t Loss: 1.690398\n",
      "CPU times: user 38min 27s, sys: 7min, total: 45min 27s\n",
      "Wall time: 6min 2s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 801/836 (96%)\n",
      "\n",
      "1/14 loss:0.10478263348340988\n",
      "2/14 loss:0.19269834458827972\n",
      "3/14 loss:0.30818143486976624\n",
      "4/14 loss:0.38977953791618347\n",
      "5/14 loss:0.16019214689731598\n",
      "6/14 loss:0.20660001039505005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/14 loss:0.17245791852474213\n",
      "8/14 loss:0.07426200062036514\n",
      "9/14 loss:0.10762886703014374\n",
      "10/14 loss:0.06251417845487595\n",
      "11/14 loss:0.06430771946907043\n",
      "12/14 loss:0.144452765583992\n",
      "13/14 loss:0.11050929129123688\n",
      "14/14 loss:0.19831059873104095\n",
      "15/14 loss:0.1593659520149231\n",
      "16/14 loss:0.045894935727119446\n",
      "17/14 loss:0.09098749607801437\n",
      "18/14 loss:0.13364188373088837\n",
      "19/14 loss:0.09893686324357986\n",
      "20/14 loss:0.09723823517560959\n",
      "21/14 loss:0.05006932094693184\n",
      "22/14 loss:0.15263304114341736\n",
      "23/14 loss:0.059094808995723724\n",
      "24/14 loss:0.052892446517944336\n",
      "25/14 loss:0.1865861564874649\n",
      "26/14 loss:0.11967360228300095\n",
      "27/14 loss:0.07765771448612213\n",
      "28/14 loss:0.03848232328891754\n",
      "29/14 loss:0.07071150094270706\n",
      "30/14 loss:0.08552324026823044\n",
      "31/14 loss:0.08183075487613678\n",
      "32/14 loss:0.038649771362543106\n",
      "33/14 loss:0.14013171195983887\n",
      "34/14 loss:0.13182294368743896\n",
      "35/14 loss:0.1112225353717804\n",
      "36/14 loss:0.0600411556661129\n",
      "37/14 loss:0.05641501396894455\n",
      "38/14 loss:0.08200245350599289\n",
      "39/14 loss:0.038942039012908936\n",
      "40/14 loss:0.07951882481575012\n",
      "41/14 loss:0.09978846460580826\n",
      "42/14 loss:0.08380668610334396\n",
      "43/14 loss:0.04398684948682785\n",
      "44/14 loss:0.07079930603504181\n",
      "45/14 loss:0.11959627270698547\n",
      "46/14 loss:0.047926075756549835\n",
      "47/14 loss:0.13125625252723694\n",
      "48/14 loss:0.07791242748498917\n",
      "49/14 loss:0.05296206474304199\n",
      "50/14 loss:0.11291837692260742\n",
      "51/14 loss:0.10831193625926971\n",
      "52/14 loss:0.11707836389541626\n",
      "53/14 loss:0.07062593102455139\n",
      "54/14 loss:0.09229729324579239\n",
      "55/14 loss:0.06266774982213974\n",
      "56/14 loss:0.06247112154960632\n",
      "57/14 loss:0.14143550395965576\n",
      "58/14 loss:0.13973410427570343\n",
      "59/14 loss:0.08088817447423935\n",
      "60/14 loss:0.11482669413089752\n",
      "61/14 loss:0.09384439885616302\n",
      "62/14 loss:0.10854446887969971\n",
      "63/14 loss:0.12332206964492798\n",
      "64/14 loss:0.09915107488632202\n",
      "65/14 loss:0.0882277563214302\n",
      "66/14 loss:0.11166753619909286\n",
      "67/14 loss:0.08782482892274857\n",
      "68/14 loss:0.05286078527569771\n",
      "69/14 loss:0.0735919177532196\n",
      "70/14 loss:0.12217433005571365\n",
      "71/14 loss:0.03774198517203331\n",
      "72/14 loss:0.041555844247341156\n",
      "73/14 loss:0.13756021857261658\n",
      "74/14 loss:0.06335022300481796\n",
      "75/14 loss:0.07988132536411285\n",
      "76/14 loss:0.1026977077126503\n",
      "77/14 loss:0.16050337255001068\n",
      "78/14 loss:0.07852631062269211\n",
      "79/14 loss:0.10237118601799011\n",
      "80/14 loss:0.13195787370204926\n",
      "81/14 loss:0.07959334552288055\n",
      "82/14 loss:0.11438263207674026\n",
      "83/14 loss:0.09194774925708771\n",
      "84/14 loss:0.14654576778411865\n",
      "85/14 loss:0.16382236778736115\n",
      "86/14 loss:0.08781736344099045\n",
      "87/14 loss:0.16945193707942963\n",
      "88/14 loss:0.03862462192773819\n",
      "89/14 loss:0.15171542763710022\n",
      "90/14 loss:0.15929432213306427\n",
      "91/14 loss:0.09879972040653229\n",
      "92/14 loss:0.060115642845630646\n",
      "93/14 loss:0.09145806729793549\n",
      "94/14 loss:0.038086678832769394\n",
      "95/14 loss:0.10329621285200119\n",
      "96/14 loss:0.17631341516971588\n",
      "97/14 loss:0.06406963616609573\n",
      "98/14 loss:0.056192636489868164\n",
      "99/14 loss:0.08700691163539886\n",
      "100/14 loss:0.0532180555164814\n",
      "101/14 loss:0.15074487030506134\n",
      "102/14 loss:0.10565105080604553\n",
      "103/14 loss:0.1258704960346222\n",
      "104/14 loss:0.12690472602844238\n",
      "105/14 loss:0.23025907576084137\n",
      "106/14 loss:0.04369980841875076\n",
      "107/14 loss:0.11759403347969055\n",
      "108/14 loss:0.10391127318143845\n",
      "109/14 loss:0.13344164192676544\n",
      "110/14 loss:0.05135515704751015\n",
      "111/14 loss:0.0984836295247078\n",
      "112/14 loss:0.05589055269956589\n",
      "113/14 loss:0.07232461869716644\n",
      "114/14 loss:0.03760765120387077\n",
      "115/14 loss:0.06806869804859161\n",
      "116/14 loss:0.09861008822917938\n",
      "117/14 loss:0.10286357998847961\n",
      "118/14 loss:0.07757528871297836\n",
      "119/14 loss:0.14175945520401\n",
      "Train Epoch: 14\t Loss: 0.141759\n",
      "CPU times: user 38min 33s, sys: 6min 59s, total: 45min 32s\n",
      "Wall time: 6min 3s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 807/836 (97%)\n",
      "\n",
      "1/15 loss:0.07802193611860275\n",
      "2/15 loss:0.12294600903987885\n",
      "3/15 loss:0.09157631546258926\n",
      "4/15 loss:0.061938878148794174\n",
      "5/15 loss:0.09382344037294388\n",
      "6/15 loss:0.08368704468011856\n",
      "7/15 loss:0.09040676802396774\n",
      "8/15 loss:0.04348073527216911\n",
      "9/15 loss:0.09846747666597366\n",
      "10/15 loss:0.025255050510168076\n",
      "11/15 loss:0.07727455347776413\n",
      "12/15 loss:0.0807659700512886\n",
      "13/15 loss:0.05143482983112335\n",
      "14/15 loss:0.12869001924991608\n",
      "15/15 loss:0.02572602592408657\n",
      "16/15 loss:0.1489678919315338\n",
      "17/15 loss:0.1568734049797058\n",
      "18/15 loss:0.04229553043842316\n",
      "19/15 loss:0.19589583575725555\n",
      "20/15 loss:0.07631929218769073\n",
      "21/15 loss:0.1057472750544548\n",
      "22/15 loss:0.10445858538150787\n",
      "23/15 loss:0.048065923154354095\n",
      "24/15 loss:0.09469511359930038\n",
      "25/15 loss:0.1276431381702423\n",
      "26/15 loss:0.13618513941764832\n",
      "27/15 loss:0.05067465081810951\n",
      "28/15 loss:0.12876364588737488\n",
      "29/15 loss:0.05517143756151199\n",
      "30/15 loss:0.09940841794013977\n",
      "31/15 loss:0.14462369680404663\n",
      "32/15 loss:0.0673675537109375\n",
      "33/15 loss:0.07618740200996399\n",
      "34/15 loss:0.06124967336654663\n",
      "35/15 loss:0.21799856424331665\n",
      "36/15 loss:0.08662930130958557\n",
      "37/15 loss:0.06396830826997757\n",
      "38/15 loss:0.09730841964483261\n",
      "39/15 loss:0.10162680596113205\n",
      "40/15 loss:0.12756624817848206\n",
      "41/15 loss:0.045641444623470306\n",
      "42/15 loss:0.05039450153708458\n",
      "43/15 loss:0.0913313552737236\n",
      "44/15 loss:0.0414838008582592\n",
      "45/15 loss:0.12635724246501923\n",
      "46/15 loss:0.06722281128168106\n",
      "47/15 loss:0.12393607944250107\n",
      "48/15 loss:0.09648402035236359\n",
      "49/15 loss:0.05695843696594238\n",
      "50/15 loss:0.12618568539619446\n",
      "51/15 loss:0.029981741681694984\n",
      "52/15 loss:0.02679263986647129\n",
      "53/15 loss:0.10951848328113556\n",
      "54/15 loss:0.13052622973918915\n",
      "55/15 loss:0.09181678295135498\n",
      "56/15 loss:0.06370183080434799\n",
      "57/15 loss:0.07729873061180115\n",
      "58/15 loss:0.06717797368764877\n",
      "59/15 loss:0.11348111182451248\n",
      "60/15 loss:0.07158692181110382\n",
      "61/15 loss:0.05765446275472641\n",
      "62/15 loss:0.0876450166106224\n",
      "63/15 loss:0.07807553559541702\n",
      "64/15 loss:0.14360935986042023\n",
      "65/15 loss:0.03623780608177185\n",
      "66/15 loss:0.08263204246759415\n",
      "67/15 loss:0.09356977045536041\n",
      "68/15 loss:0.04226308688521385\n",
      "69/15 loss:0.11418504267930984\n",
      "70/15 loss:0.11585775017738342\n",
      "71/15 loss:0.0754508525133133\n",
      "72/15 loss:0.11740827560424805\n",
      "73/15 loss:0.04997040331363678\n",
      "74/15 loss:0.12377680838108063\n",
      "75/15 loss:0.07889824360609055\n",
      "76/15 loss:0.09589040279388428\n",
      "77/15 loss:0.056272465735673904\n",
      "78/15 loss:0.10007248818874359\n",
      "79/15 loss:0.07154466211795807\n",
      "80/15 loss:0.0932222306728363\n",
      "81/15 loss:0.13715310394763947\n",
      "82/15 loss:0.08295654505491257\n",
      "83/15 loss:0.05021687597036362\n",
      "84/15 loss:0.09369517117738724\n",
      "85/15 loss:0.10616081207990646\n",
      "86/15 loss:0.07080494612455368\n",
      "87/15 loss:0.09900502860546112\n",
      "88/15 loss:0.13824139535427094\n",
      "89/15 loss:0.056992895901203156\n",
      "90/15 loss:0.11011718213558197\n",
      "91/15 loss:0.11571203172206879\n",
      "92/15 loss:0.06472171097993851\n",
      "93/15 loss:0.10419420152902603\n",
      "94/15 loss:0.07442444562911987\n",
      "95/15 loss:0.05058368667960167\n",
      "96/15 loss:0.12061809003353119\n",
      "97/15 loss:0.046165645122528076\n",
      "98/15 loss:0.08274096250534058\n",
      "99/15 loss:0.0850217342376709\n",
      "100/15 loss:0.18249480426311493\n",
      "101/15 loss:0.04707299545407295\n",
      "102/15 loss:0.11188746243715286\n",
      "103/15 loss:0.10532542318105698\n",
      "104/15 loss:0.09666881710290909\n",
      "105/15 loss:0.09484919160604477\n",
      "106/15 loss:0.11208178102970123\n",
      "107/15 loss:0.11862417310476303\n",
      "108/15 loss:0.08380486071109772\n",
      "109/15 loss:0.09107958525419235\n",
      "110/15 loss:0.05693203955888748\n",
      "111/15 loss:0.18062953650951385\n",
      "112/15 loss:0.08280862122774124\n",
      "113/15 loss:0.05951613560318947\n",
      "114/15 loss:0.05925912782549858\n",
      "115/15 loss:0.11073765903711319\n",
      "116/15 loss:0.03854772448539734\n",
      "117/15 loss:0.04644244909286499\n",
      "118/15 loss:0.15641553699970245\n",
      "119/15 loss:0.1463162899017334\n",
      "Train Epoch: 15\t Loss: 0.146316\n",
      "CPU times: user 38min 33s, sys: 6min 58s, total: 45min 32s\n",
      "Wall time: 6min 3s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 802/836 (96%)\n",
      "\n",
      "1/16 loss:0.0971156507730484\n",
      "2/16 loss:0.062369294464588165\n",
      "3/16 loss:0.12899400293827057\n",
      "4/16 loss:0.05694855377078056\n",
      "5/16 loss:0.1846563220024109\n",
      "6/16 loss:0.09479072690010071\n",
      "7/16 loss:0.05423533171415329\n",
      "8/16 loss:0.13907143473625183\n",
      "9/16 loss:0.057948771864175797\n",
      "10/16 loss:0.050346750766038895\n",
      "11/16 loss:0.07412997633218765\n",
      "12/16 loss:0.12605375051498413\n",
      "13/16 loss:0.12638677656650543\n",
      "14/16 loss:0.08552936464548111\n",
      "15/16 loss:0.0580892413854599\n",
      "16/16 loss:0.042708758264780045\n",
      "17/16 loss:0.11326726526021957\n",
      "18/16 loss:0.09619589149951935\n",
      "19/16 loss:0.08194274455308914\n",
      "20/16 loss:0.0794476717710495\n",
      "21/16 loss:0.10103117674589157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/16 loss:0.0736323893070221\n",
      "23/16 loss:0.07138867676258087\n",
      "24/16 loss:0.049243468791246414\n",
      "25/16 loss:0.12986843287944794\n",
      "26/16 loss:0.10679905116558075\n",
      "27/16 loss:0.1264168918132782\n",
      "28/16 loss:0.09381138533353806\n",
      "29/16 loss:0.12111742049455643\n",
      "30/16 loss:0.08879920095205307\n",
      "31/16 loss:0.062063150107860565\n",
      "32/16 loss:0.07554272562265396\n",
      "33/16 loss:0.15940670669078827\n",
      "34/16 loss:0.09734372794628143\n",
      "35/16 loss:0.05060652270913124\n",
      "36/16 loss:0.07336673885583878\n",
      "37/16 loss:0.09989132732152939\n",
      "38/16 loss:0.07162454724311829\n",
      "39/16 loss:0.20456252992153168\n",
      "40/16 loss:0.08691518753767014\n",
      "41/16 loss:0.0543694905936718\n",
      "42/16 loss:0.09703050553798676\n",
      "43/16 loss:0.06492253392934799\n",
      "44/16 loss:0.0662383958697319\n",
      "45/16 loss:0.06802587956190109\n",
      "46/16 loss:0.128035306930542\n",
      "47/16 loss:0.11556234210729599\n",
      "48/16 loss:0.02724122814834118\n",
      "49/16 loss:0.10866988450288773\n",
      "50/16 loss:0.10451076179742813\n",
      "51/16 loss:0.07014685124158859\n",
      "52/16 loss:0.06729098409414291\n",
      "53/16 loss:0.06879507750272751\n",
      "54/16 loss:0.06842534244060516\n",
      "55/16 loss:0.05879721790552139\n",
      "56/16 loss:0.042833361774683\n",
      "57/16 loss:0.10719079524278641\n",
      "58/16 loss:0.10453667491674423\n",
      "59/16 loss:0.0984106957912445\n",
      "60/16 loss:0.04405924305319786\n",
      "61/16 loss:0.11367787420749664\n",
      "62/16 loss:0.14587250351905823\n",
      "63/16 loss:0.051026564091444016\n",
      "64/16 loss:0.03953598067164421\n",
      "65/16 loss:0.09706898033618927\n",
      "66/16 loss:0.042107515037059784\n",
      "67/16 loss:0.035941142588853836\n",
      "68/16 loss:0.07560765743255615\n",
      "69/16 loss:0.09146006405353546\n",
      "70/16 loss:0.05347959324717522\n",
      "71/16 loss:0.0954200029373169\n",
      "72/16 loss:0.12226522713899612\n",
      "73/16 loss:0.09276425093412399\n",
      "74/16 loss:0.043138571083545685\n",
      "75/16 loss:0.05564621835947037\n",
      "76/16 loss:0.051244720816612244\n",
      "77/16 loss:0.03974320366978645\n",
      "78/16 loss:0.07282762974500656\n",
      "79/16 loss:0.09176933020353317\n",
      "80/16 loss:0.054512668401002884\n",
      "81/16 loss:0.04233549162745476\n",
      "82/16 loss:0.07526037096977234\n",
      "83/16 loss:0.05081235244870186\n",
      "84/16 loss:0.09367118030786514\n",
      "85/16 loss:0.0674138218164444\n",
      "86/16 loss:0.09231552481651306\n",
      "87/16 loss:0.08585229516029358\n",
      "88/16 loss:0.1293393224477768\n",
      "89/16 loss:0.09191640466451645\n",
      "90/16 loss:0.07498010993003845\n",
      "91/16 loss:0.14353767037391663\n",
      "92/16 loss:0.019575560465455055\n",
      "93/16 loss:0.07781495898962021\n",
      "94/16 loss:0.16191165149211884\n",
      "95/16 loss:0.06419958919286728\n",
      "96/16 loss:0.034686677157878876\n",
      "97/16 loss:0.052120838314294815\n",
      "98/16 loss:0.1238650530576706\n",
      "99/16 loss:0.16724711656570435\n",
      "100/16 loss:0.15557867288589478\n",
      "101/16 loss:0.07196060568094254\n",
      "102/16 loss:0.12717999517917633\n",
      "103/16 loss:0.09672714024782181\n",
      "104/16 loss:0.09619211405515671\n",
      "105/16 loss:0.08870422095060349\n",
      "106/16 loss:0.10599002242088318\n",
      "107/16 loss:0.06672278046607971\n",
      "108/16 loss:0.06386564671993256\n",
      "109/16 loss:0.08419517427682877\n",
      "110/16 loss:0.04808632656931877\n",
      "111/16 loss:0.11578971892595291\n",
      "112/16 loss:0.1869274377822876\n",
      "113/16 loss:0.052962567657232285\n",
      "114/16 loss:0.1660507768392563\n",
      "115/16 loss:0.12836331129074097\n",
      "116/16 loss:0.09482117742300034\n",
      "117/16 loss:0.07378231734037399\n",
      "118/16 loss:0.0902998223900795\n",
      "119/16 loss:0.21105824410915375\n",
      "Train Epoch: 16\t Loss: 0.211058\n",
      "CPU times: user 38min 31s, sys: 6min 51s, total: 45min 23s\n",
      "Wall time: 6min 2s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 807/836 (97%)\n",
      "\n",
      "1/17 loss:0.03837835043668747\n",
      "2/17 loss:0.11290591955184937\n",
      "3/17 loss:0.08839772641658783\n",
      "4/17 loss:0.07375317811965942\n",
      "5/17 loss:0.11504878848791122\n",
      "6/17 loss:0.08193422853946686\n",
      "7/17 loss:0.08099474757909775\n",
      "8/17 loss:0.14795275032520294\n",
      "9/17 loss:0.0942227765917778\n",
      "10/17 loss:0.07211565971374512\n",
      "11/17 loss:0.10854578763246536\n",
      "12/17 loss:0.09083671122789383\n",
      "13/17 loss:0.09781339764595032\n",
      "14/17 loss:0.17518091201782227\n",
      "15/17 loss:0.14524470269680023\n",
      "16/17 loss:0.04469665512442589\n",
      "17/17 loss:0.04151472449302673\n",
      "18/17 loss:0.04778227582573891\n",
      "19/17 loss:0.13574187457561493\n",
      "20/17 loss:0.1653190702199936\n",
      "21/17 loss:0.0915284976363182\n",
      "22/17 loss:0.0950627401471138\n",
      "23/17 loss:0.11212266981601715\n",
      "24/17 loss:0.1384703367948532\n",
      "25/17 loss:0.13572543859481812\n",
      "26/17 loss:0.07498961687088013\n",
      "27/17 loss:0.10213033109903336\n",
      "28/17 loss:0.05642857030034065\n",
      "29/17 loss:0.04824746027588844\n",
      "30/17 loss:0.1777711808681488\n",
      "31/17 loss:0.04808788746595383\n",
      "32/17 loss:0.09759943187236786\n",
      "33/17 loss:0.10985453426837921\n",
      "34/17 loss:0.08506947755813599\n",
      "35/17 loss:0.045923542231321335\n",
      "36/17 loss:0.09937199205160141\n",
      "37/17 loss:0.0613972544670105\n",
      "38/17 loss:0.10747785866260529\n",
      "39/17 loss:0.12804946303367615\n",
      "40/17 loss:0.11049503833055496\n",
      "41/17 loss:0.14552804827690125\n",
      "42/17 loss:0.07646698504686356\n",
      "43/17 loss:0.15559403598308563\n",
      "44/17 loss:0.029199372977018356\n",
      "45/17 loss:0.02440183237195015\n",
      "46/17 loss:0.059429802000522614\n",
      "47/17 loss:0.09270577877759933\n",
      "48/17 loss:0.1832631677389145\n",
      "49/17 loss:0.14174751937389374\n",
      "50/17 loss:0.09767145663499832\n",
      "51/17 loss:0.12843312323093414\n",
      "52/17 loss:0.11502234637737274\n",
      "53/17 loss:0.07823822647333145\n",
      "54/17 loss:0.08235806226730347\n",
      "55/17 loss:0.08661921322345734\n",
      "56/17 loss:0.14291498064994812\n",
      "57/17 loss:0.08498061448335648\n",
      "58/17 loss:0.10419020801782608\n",
      "59/17 loss:0.05004759505391121\n",
      "60/17 loss:0.14725971221923828\n",
      "61/17 loss:0.11040670424699783\n",
      "62/17 loss:0.08344217389822006\n",
      "63/17 loss:0.0490792840719223\n",
      "64/17 loss:0.038857005536556244\n",
      "65/17 loss:0.04844468832015991\n",
      "66/17 loss:0.07475192844867706\n",
      "67/17 loss:0.14534272253513336\n",
      "68/17 loss:0.05160856992006302\n",
      "69/17 loss:0.11710649728775024\n",
      "70/17 loss:0.12337782979011536\n",
      "71/17 loss:0.05682951584458351\n",
      "72/17 loss:0.0940590351819992\n",
      "73/17 loss:0.04548252001404762\n",
      "74/17 loss:0.07293642312288284\n",
      "75/17 loss:0.08149001002311707\n",
      "76/17 loss:0.13632887601852417\n",
      "77/17 loss:0.07221425324678421\n",
      "78/17 loss:0.14808200299739838\n",
      "79/17 loss:0.09880711138248444\n",
      "80/17 loss:0.1122119128704071\n",
      "81/17 loss:0.08098813891410828\n",
      "82/17 loss:0.15206769108772278\n",
      "83/17 loss:0.05532391741871834\n",
      "84/17 loss:0.04815366491675377\n",
      "85/17 loss:0.126754492521286\n",
      "86/17 loss:0.08732952177524567\n",
      "87/17 loss:0.06560167670249939\n",
      "88/17 loss:0.1085318922996521\n",
      "89/17 loss:0.08014208823442459\n",
      "90/17 loss:0.11282540112733841\n",
      "91/17 loss:0.043328169733285904\n",
      "92/17 loss:0.1697414219379425\n",
      "93/17 loss:0.08748948574066162\n",
      "94/17 loss:0.06068861484527588\n",
      "95/17 loss:0.035411715507507324\n",
      "96/17 loss:0.20554572343826294\n",
      "97/17 loss:0.1644563525915146\n",
      "98/17 loss:0.08701834082603455\n",
      "99/17 loss:0.060755934566259384\n",
      "100/17 loss:0.07882074266672134\n",
      "101/17 loss:0.17197634279727936\n",
      "102/17 loss:0.10477854311466217\n",
      "103/17 loss:0.08532053232192993\n",
      "104/17 loss:0.11856267601251602\n",
      "105/17 loss:0.1169603019952774\n",
      "106/17 loss:0.0212702639400959\n",
      "107/17 loss:0.07037898153066635\n",
      "108/17 loss:0.1310720294713974\n",
      "109/17 loss:0.06565484404563904\n",
      "110/17 loss:0.1285647600889206\n",
      "111/17 loss:0.08456981182098389\n",
      "112/17 loss:0.08063127100467682\n",
      "113/17 loss:0.0830952376127243\n",
      "114/17 loss:0.06115707755088806\n",
      "115/17 loss:0.10556430369615555\n",
      "116/17 loss:0.10355473309755325\n",
      "117/17 loss:0.13227832317352295\n",
      "118/17 loss:0.10892824828624725\n",
      "119/17 loss:0.09340891987085342\n",
      "Train Epoch: 17\t Loss: 0.093409\n",
      "CPU times: user 38min 25s, sys: 6min 53s, total: 45min 18s\n",
      "Wall time: 6min 1s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 809/836 (97%)\n",
      "\n",
      "1/18 loss:0.059593565762043\n",
      "2/18 loss:0.05685335770249367\n",
      "3/18 loss:0.09911440312862396\n",
      "4/18 loss:0.0918109193444252\n",
      "5/18 loss:0.09738083928823471\n",
      "6/18 loss:0.12265358120203018\n",
      "7/18 loss:0.07270892709493637\n",
      "8/18 loss:0.11601132899522781\n",
      "9/18 loss:0.07494999468326569\n",
      "10/18 loss:0.05428454279899597\n",
      "11/18 loss:0.17560730874538422\n",
      "12/18 loss:0.13838662207126617\n",
      "13/18 loss:0.0878937840461731\n",
      "14/18 loss:0.21951846778392792\n",
      "15/18 loss:0.12701396644115448\n",
      "16/18 loss:0.1556345373392105\n",
      "17/18 loss:0.08747360855340958\n",
      "18/18 loss:0.10123912990093231\n",
      "19/18 loss:0.1032942682504654\n",
      "20/18 loss:0.13441665470600128\n",
      "21/18 loss:0.25190043449401855\n",
      "22/18 loss:0.07472240924835205\n",
      "23/18 loss:0.09584937244653702\n",
      "24/18 loss:0.08369904011487961\n",
      "25/18 loss:0.18770051002502441\n",
      "26/18 loss:0.04219403862953186\n",
      "27/18 loss:0.07699321210384369\n",
      "28/18 loss:0.0411674827337265\n",
      "29/18 loss:0.16601957380771637\n",
      "30/18 loss:0.07072561234235764\n",
      "31/18 loss:0.09039374440908432\n",
      "32/18 loss:0.03761656582355499\n",
      "33/18 loss:0.0574871301651001\n",
      "34/18 loss:0.11194305866956711\n",
      "35/18 loss:0.14980854094028473\n",
      "36/18 loss:0.0875014215707779\n",
      "37/18 loss:0.07933823019266129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/18 loss:0.17862744629383087\n",
      "39/18 loss:0.08471589535474777\n",
      "40/18 loss:0.0415969118475914\n",
      "41/18 loss:0.05149511620402336\n",
      "42/18 loss:0.07533708214759827\n",
      "43/18 loss:0.09611373394727707\n",
      "44/18 loss:0.141941100358963\n",
      "45/18 loss:0.0469394214451313\n",
      "46/18 loss:0.06292156130075455\n",
      "47/18 loss:0.06150958687067032\n",
      "48/18 loss:0.09232722222805023\n",
      "49/18 loss:0.15443183481693268\n",
      "50/18 loss:0.05117364972829819\n",
      "51/18 loss:0.03019029088318348\n",
      "52/18 loss:0.07679186761379242\n",
      "53/18 loss:0.030219264328479767\n",
      "54/18 loss:0.08056724071502686\n",
      "55/18 loss:0.07540813088417053\n",
      "56/18 loss:0.038207944482564926\n",
      "57/18 loss:0.09087507426738739\n",
      "58/18 loss:0.032407067716121674\n",
      "59/18 loss:0.10683148354291916\n",
      "60/18 loss:0.12796804308891296\n",
      "61/18 loss:0.11967551708221436\n",
      "62/18 loss:0.08214785158634186\n",
      "63/18 loss:0.08964499831199646\n",
      "64/18 loss:0.11095625162124634\n",
      "65/18 loss:0.0648413598537445\n",
      "66/18 loss:0.1521821916103363\n",
      "67/18 loss:0.05825185775756836\n",
      "68/18 loss:0.0883314460515976\n",
      "69/18 loss:0.06940530985593796\n",
      "70/18 loss:0.108612060546875\n",
      "71/18 loss:0.07005152851343155\n",
      "72/18 loss:0.10726414620876312\n",
      "73/18 loss:0.044515784829854965\n",
      "74/18 loss:0.08642858266830444\n",
      "75/18 loss:0.11309049278497696\n",
      "76/18 loss:0.03482890874147415\n",
      "77/18 loss:0.18698574602603912\n",
      "78/18 loss:0.07831723242998123\n",
      "79/18 loss:0.08320935070514679\n",
      "80/18 loss:0.045208461582660675\n",
      "81/18 loss:0.12762446701526642\n",
      "82/18 loss:0.08332245796918869\n",
      "83/18 loss:0.1692638397216797\n",
      "84/18 loss:0.20177435874938965\n",
      "85/18 loss:0.08931373804807663\n",
      "86/18 loss:0.10675448179244995\n",
      "87/18 loss:0.10309118777513504\n",
      "88/18 loss:0.05049753934144974\n",
      "89/18 loss:0.07462016493082047\n",
      "90/18 loss:0.03859458863735199\n",
      "91/18 loss:0.0783771201968193\n",
      "92/18 loss:0.05370057374238968\n",
      "93/18 loss:0.07237300276756287\n",
      "94/18 loss:0.05026160553097725\n",
      "95/18 loss:0.11010444164276123\n",
      "96/18 loss:0.06809911876916885\n",
      "97/18 loss:0.0938306674361229\n",
      "98/18 loss:0.08752056956291199\n",
      "99/18 loss:0.10169454663991928\n",
      "100/18 loss:0.06846877932548523\n",
      "101/18 loss:0.0491262823343277\n",
      "102/18 loss:0.04630820080637932\n",
      "103/18 loss:0.13962422311306\n",
      "104/18 loss:0.08572026342153549\n",
      "105/18 loss:0.06766363978385925\n",
      "106/18 loss:0.1327177733182907\n",
      "107/18 loss:0.03324997052550316\n",
      "108/18 loss:0.12650611996650696\n",
      "109/18 loss:0.036779891699552536\n",
      "110/18 loss:0.16817496716976166\n",
      "111/18 loss:0.2051018625497818\n",
      "112/18 loss:0.12523484230041504\n",
      "113/18 loss:0.09457480907440186\n",
      "114/18 loss:0.0890231505036354\n",
      "115/18 loss:0.10669991374015808\n",
      "116/18 loss:0.08417905122041702\n",
      "117/18 loss:0.17424549162387848\n",
      "118/18 loss:0.07861589640378952\n",
      "119/18 loss:0.3304649293422699\n",
      "Train Epoch: 18\t Loss: 0.330465\n",
      "CPU times: user 38min 23s, sys: 6min 51s, total: 45min 14s\n",
      "Wall time: 6min\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 802/836 (96%)\n",
      "\n",
      "1/19 loss:0.16105172038078308\n",
      "2/19 loss:0.05842338502407074\n",
      "3/19 loss:0.13132977485656738\n",
      "4/19 loss:0.10503226518630981\n",
      "5/19 loss:0.07770230621099472\n",
      "6/19 loss:0.056464385241270065\n",
      "7/19 loss:0.12926754355430603\n",
      "8/19 loss:0.20223242044448853\n",
      "9/19 loss:0.056739240884780884\n",
      "10/19 loss:0.16046829521656036\n",
      "11/19 loss:0.15062451362609863\n",
      "12/19 loss:0.07296238839626312\n",
      "13/19 loss:0.03928300738334656\n",
      "14/19 loss:0.253318727016449\n",
      "15/19 loss:0.12102816998958588\n",
      "16/19 loss:0.09703199565410614\n",
      "17/19 loss:0.11008903384208679\n",
      "18/19 loss:0.07208922505378723\n",
      "19/19 loss:0.041646018624305725\n",
      "20/19 loss:0.07147230207920074\n",
      "21/19 loss:0.07313895970582962\n",
      "22/19 loss:0.17326968908309937\n",
      "23/19 loss:0.1823553591966629\n",
      "24/19 loss:0.03668874129652977\n",
      "25/19 loss:0.03947722166776657\n",
      "26/19 loss:0.0871933326125145\n",
      "27/19 loss:0.12492835521697998\n",
      "28/19 loss:0.08792147785425186\n",
      "29/19 loss:0.08189824968576431\n",
      "30/19 loss:0.10599622130393982\n",
      "31/19 loss:0.20179100334644318\n",
      "32/19 loss:0.10790100693702698\n",
      "33/19 loss:0.061509329825639725\n",
      "34/19 loss:0.21392250061035156\n",
      "35/19 loss:0.1423211693763733\n",
      "36/19 loss:0.18118564784526825\n",
      "37/19 loss:0.05268331989645958\n",
      "38/19 loss:0.09177950024604797\n",
      "39/19 loss:0.12521541118621826\n",
      "40/19 loss:0.07674156129360199\n",
      "41/19 loss:0.11477016657590866\n",
      "42/19 loss:0.06160612776875496\n",
      "43/19 loss:0.29904693365097046\n",
      "44/19 loss:0.11977183818817139\n",
      "45/19 loss:0.0856475830078125\n",
      "46/19 loss:0.08654174953699112\n",
      "47/19 loss:0.025113029405474663\n",
      "48/19 loss:0.16294310986995697\n",
      "49/19 loss:0.15349909663200378\n",
      "50/19 loss:0.11308788508176804\n",
      "51/19 loss:0.0732516422867775\n",
      "52/19 loss:0.09275145828723907\n",
      "53/19 loss:0.16842298209667206\n",
      "54/19 loss:0.053210414946079254\n",
      "55/19 loss:0.05836626887321472\n",
      "56/19 loss:0.1518862098455429\n",
      "57/19 loss:0.08490326255559921\n",
      "58/19 loss:0.14934787154197693\n",
      "59/19 loss:0.09886354953050613\n",
      "60/19 loss:0.07152678817510605\n",
      "61/19 loss:0.08473163098096848\n",
      "62/19 loss:0.1493351012468338\n",
      "63/19 loss:0.14956621825695038\n",
      "64/19 loss:0.0678689032793045\n",
      "65/19 loss:0.12856294214725494\n",
      "66/19 loss:0.14414988458156586\n",
      "67/19 loss:0.10605424642562866\n",
      "68/19 loss:0.050369225442409515\n",
      "69/19 loss:0.13584758341312408\n",
      "70/19 loss:0.12225590646266937\n",
      "71/19 loss:0.04922730475664139\n",
      "72/19 loss:0.04405123367905617\n",
      "73/19 loss:0.11243435740470886\n",
      "74/19 loss:0.06767138838768005\n",
      "75/19 loss:0.0740879625082016\n",
      "76/19 loss:0.07804003357887268\n",
      "77/19 loss:0.07928607612848282\n",
      "78/19 loss:0.08416469395160675\n",
      "79/19 loss:0.06815217435359955\n",
      "80/19 loss:0.08177416026592255\n",
      "81/19 loss:0.06049136072397232\n",
      "82/19 loss:0.13820169866085052\n",
      "83/19 loss:0.06827940046787262\n",
      "84/19 loss:0.10026001185178757\n",
      "85/19 loss:0.07728685438632965\n",
      "86/19 loss:0.051711305975914\n",
      "87/19 loss:0.06830023974180222\n",
      "88/19 loss:0.09458901733160019\n",
      "89/19 loss:0.16090577840805054\n",
      "90/19 loss:0.06970228254795074\n",
      "91/19 loss:0.1112329363822937\n",
      "92/19 loss:0.1100761815905571\n",
      "93/19 loss:0.1052078977227211\n",
      "94/19 loss:0.031075207516551018\n",
      "95/19 loss:0.097730353474617\n",
      "96/19 loss:0.06870828568935394\n",
      "97/19 loss:0.04255608841776848\n",
      "98/19 loss:0.13868330419063568\n",
      "99/19 loss:0.06956731528043747\n",
      "100/19 loss:0.1347164511680603\n",
      "101/19 loss:0.09064038842916489\n",
      "102/19 loss:0.0828297808766365\n",
      "103/19 loss:0.11053135991096497\n",
      "104/19 loss:0.039739713072776794\n",
      "105/19 loss:0.07909373193979263\n",
      "106/19 loss:0.08106371760368347\n",
      "107/19 loss:0.05413704365491867\n",
      "108/19 loss:0.08183460682630539\n",
      "109/19 loss:0.16994719207286835\n",
      "110/19 loss:0.12758757174015045\n",
      "111/19 loss:0.04639684036374092\n",
      "112/19 loss:0.20982304215431213\n",
      "113/19 loss:0.10111036151647568\n",
      "114/19 loss:0.06908329576253891\n",
      "115/19 loss:0.05440502613782883\n",
      "116/19 loss:0.07839462161064148\n",
      "117/19 loss:0.13053272664546967\n",
      "118/19 loss:0.18113507330417633\n",
      "119/19 loss:0.010723992250859737\n",
      "Train Epoch: 19\t Loss: 0.010724\n",
      "CPU times: user 38min 17s, sys: 6min 52s, total: 45min 10s\n",
      "Wall time: 5min 59s\n",
      "i: 13\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 798/836 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20):\n",
    "    %time train(model_ft, criterion, optimizer, device=\"cpu\", train_loader=dataloaders[\"train\"],epoch=epoch)\n",
    "    test(model_ft, criterion, optimizer, device=\"cpu\", test_loader=dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 只保存状态字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 只保存状态字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"model_ft.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(\"model_ft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存整个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, \"model_ft_total.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load( \"model_ft_total.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images = 6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    images_so_far = 0\n",
    "    plt.figure()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloaders[\"val\"]):\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predict = torch.max(outputs, 1)\n",
    "            \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis(\"off\")\n",
    "                ax.set_title(\"predicted:{}\".format(predict[j]))\n",
    "                \n",
    "                image_show(inputs.cpu().data[j])\n",
    "                \n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode = was_training)\n",
    "                    return\n",
    "                model.train(mode = was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(net)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
